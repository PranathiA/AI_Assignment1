{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.callbacks import ReduceLROnPlateau,CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train/=255\n",
    "X_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = X_train[50000:][:]\n",
    "X_train = X_train[:50000][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validation = Y_train[50000:][:]\n",
    "Y_train = Y_train[:50000][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_iterations = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.3585 - acc: 0.8889Epoch 00001: val_loss improved from inf to 0.14117, saving model to Checkpoint_0.01_model256.hdf5\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.3582 - acc: 0.8891 - val_loss: 0.1412 - val_acc: 0.9590\n",
      "Epoch 2/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2643 - acc: 0.9220Epoch 00002: val_loss improved from 0.14117 to 0.13041, saving model to Checkpoint_0.01_model256.hdf5\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.2646 - acc: 0.9220 - val_loss: 0.1304 - val_acc: 0.9618\n",
      "Epoch 3/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2421 - acc: 0.9283Epoch 00003: val_loss improved from 0.13041 to 0.12023, saving model to Checkpoint_0.01_model256.hdf5\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 0.2420 - acc: 0.9283 - val_loss: 0.1202 - val_acc: 0.9663\n",
      "Epoch 4/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2321 - acc: 0.9333Epoch 00004: val_loss did not improve\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.2320 - acc: 0.9334 - val_loss: 0.1207 - val_acc: 0.9685\n",
      "Epoch 5/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2150 - acc: 0.9391Epoch 00005: val_loss did not improve\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.2151 - acc: 0.9392 - val_loss: 0.1314 - val_acc: 0.9647\n",
      "Epoch 6/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9373Epoch 00006: val_loss did not improve\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 0.2232 - acc: 0.9372 - val_loss: 0.1273 - val_acc: 0.9689\n",
      "Epoch 7/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2076 - acc: 0.9439Epoch 00007: val_loss did not improve\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 0.2074 - acc: 0.9439 - val_loss: 0.1345 - val_acc: 0.9689\n",
      "Epoch 8/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2171 - acc: 0.9407Epoch 00008: val_loss did not improve\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.2170 - acc: 0.9406 - val_loss: 0.1306 - val_acc: 0.9707\n",
      "Epoch 9/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9448- ETA: 1s - loss: 0.Epoch 00009: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 0.2020 - acc: 0.9447 - val_loss: 0.1363 - val_acc: 0.9697\n",
      "Epoch 10/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2079 - acc: 0.9463Epoch 00010: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 270us/step - loss: 0.2077 - acc: 0.9463 - val_loss: 0.1384 - val_acc: 0.9698\n",
      "Epoch 11/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.2035 - acc: 0.9467Epoch 00011: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 0.2040 - acc: 0.9465 - val_loss: 0.1455 - val_acc: 0.9681\n",
      "Epoch 12/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2027 - acc: 0.9464Epoch 00012: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 274us/step - loss: 0.2027 - acc: 0.9463 - val_loss: 0.1387 - val_acc: 0.9697\n",
      "Epoch 13/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.1894 - acc: 0.9507Epoch 00013: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 274us/step - loss: 0.1891 - acc: 0.9508 - val_loss: 0.1490 - val_acc: 0.9692\n",
      "Epoch 14/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.1890 - acc: 0.9504Epoch 00014: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 276us/step - loss: 0.1888 - acc: 0.9505 - val_loss: 0.1339 - val_acc: 0.9715\n",
      "Epoch 15/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2040 - acc: 0.9485Epoch 00015: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 276us/step - loss: 0.2039 - acc: 0.9485 - val_loss: 0.1440 - val_acc: 0.9702\n",
      "Epoch 16/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9515Epoch 00016: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 277us/step - loss: 0.1956 - acc: 0.9515 - val_loss: 0.1380 - val_acc: 0.9733\n",
      "Epoch 17/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.1812 - acc: 0.9531Epoch 00017: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 274us/step - loss: 0.1810 - acc: 0.9532 - val_loss: 0.1465 - val_acc: 0.9710\n",
      "Epoch 18/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.1930 - acc: 0.9510Epoch 00018: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 274us/step - loss: 0.1926 - acc: 0.9511 - val_loss: 0.1327 - val_acc: 0.9723\n",
      "Epoch 19/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.1826 - acc: 0.9543Epoch 00019: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 278us/step - loss: 0.1824 - acc: 0.9544 - val_loss: 0.1471 - val_acc: 0.9699\n",
      "Epoch 20/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1815 - acc: 0.9547Epoch 00020: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 279us/step - loss: 0.1815 - acc: 0.9548 - val_loss: 0.1496 - val_acc: 0.9708\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "csv_logger = CSVLogger('Results_0.01_model256'+'.csv')\n",
    "model_checkpoint = ModelCheckpoint('Checkpoint_0.01_model256'+'.hdf5',monitor = 'val_loss',\n",
    "                                    verbose = 1, save_best_only = True)\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_iterations,\n",
    "                    verbose = 1, validation_data = (X_validation, Y_validation),callbacks=[csv_logger,model_checkpoint])\n",
    "score = model.evaluate(X_validation, Y_validation, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(600, input_shape=(784,)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.3623 - acc: 0.8915Epoch 00001: val_loss improved from inf to 0.15711, saving model to Checkpoint_0.01_model600.hdf5\n",
      "50000/50000 [==============================] - 24s 472us/step - loss: 0.3622 - acc: 0.8915 - val_loss: 0.1571 - val_acc: 0.9508\n",
      "Epoch 2/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2598 - acc: 0.9248Epoch 00002: val_loss improved from 0.15711 to 0.13564, saving model to Checkpoint_0.01_model600.hdf5\n",
      "50000/50000 [==============================] - 25s 505us/step - loss: 0.2598 - acc: 0.9248 - val_loss: 0.1356 - val_acc: 0.9627\n",
      "Epoch 3/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.9330Epoch 00003: val_loss improved from 0.13564 to 0.12495, saving model to Checkpoint_0.01_model600.hdf5\n",
      "50000/50000 [==============================] - 31s 614us/step - loss: 0.2429 - acc: 0.9330 - val_loss: 0.1249 - val_acc: 0.9659\n",
      "Epoch 4/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2272 - acc: 0.9377Epoch 00004: val_loss improved from 0.12495 to 0.12473, saving model to Checkpoint_0.01_model600.hdf5\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.2276 - acc: 0.9377 - val_loss: 0.1247 - val_acc: 0.9668\n",
      "Epoch 5/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9412Epoch 00005: val_loss did not improve\n",
      "50000/50000 [==============================] - 31s 619us/step - loss: 0.2131 - acc: 0.9413 - val_loss: 0.1387 - val_acc: 0.9669\n",
      "Epoch 6/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2244 - acc: 0.9405Epoch 00006: val_loss did not improve\n",
      "50000/50000 [==============================] - 31s 623us/step - loss: 0.2243 - acc: 0.9405 - val_loss: 0.1253 - val_acc: 0.9700\n",
      "Epoch 7/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2204 - acc: 0.9436Epoch 00007: val_loss did not improve\n",
      "50000/50000 [==============================] - 31s 619us/step - loss: 0.2203 - acc: 0.9436 - val_loss: 0.1331 - val_acc: 0.9675\n",
      "Epoch 8/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2143 - acc: 0.9447Epoch 00008: val_loss did not improve\n",
      "50000/50000 [==============================] - 32s 631us/step - loss: 0.2143 - acc: 0.9448 - val_loss: 0.1302 - val_acc: 0.9709\n",
      "Epoch 9/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2092 - acc: 0.9463Epoch 00009: val_loss did not improve\n",
      "50000/50000 [==============================] - 31s 629us/step - loss: 0.2098 - acc: 0.9462 - val_loss: 0.1322 - val_acc: 0.9713\n",
      "Epoch 10/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2033 - acc: 0.9494Epoch 00010: val_loss did not improve\n",
      "50000/50000 [==============================] - 32s 636us/step - loss: 0.2036 - acc: 0.9494 - val_loss: 0.1278 - val_acc: 0.9722\n",
      "Epoch 11/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2045 - acc: 0.9502Epoch 00011: val_loss did not improve\n",
      "50000/50000 [==============================] - 32s 640us/step - loss: 0.2046 - acc: 0.9502 - val_loss: 0.1350 - val_acc: 0.9709\n",
      "Epoch 12/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9506Epoch 00012: val_loss did not improve\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.1984 - acc: 0.9505 - val_loss: 0.1556 - val_acc: 0.9707\n",
      "Epoch 13/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1971 - acc: 0.9539Epoch 00013: val_loss did not improve\n",
      "50000/50000 [==============================] - 33s 655us/step - loss: 0.1969 - acc: 0.9540 - val_loss: 0.1365 - val_acc: 0.9740\n",
      "Epoch 14/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1963 - acc: 0.9515Epoch 00014: val_loss did not improve\n",
      "50000/50000 [==============================] - 33s 651us/step - loss: 0.1963 - acc: 0.9515 - val_loss: 0.1319 - val_acc: 0.9718\n",
      "Epoch 15/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9525Epoch 00015: val_loss did not improve\n",
      "50000/50000 [==============================] - 33s 660us/step - loss: 0.1986 - acc: 0.9525 - val_loss: 0.1505 - val_acc: 0.9703\n",
      "Epoch 16/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1878 - acc: 0.9561Epoch 00016: val_loss did not improve\n",
      "50000/50000 [==============================] - 33s 664us/step - loss: 0.1876 - acc: 0.9562 - val_loss: 0.1508 - val_acc: 0.9724\n",
      "Epoch 17/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1992 - acc: 0.9544Epoch 00017: val_loss did not improve\n",
      "50000/50000 [==============================] - 33s 663us/step - loss: 0.1992 - acc: 0.9544 - val_loss: 0.1527 - val_acc: 0.9718\n",
      "Epoch 18/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1847 - acc: 0.9578Epoch 00018: val_loss did not improve\n",
      "50000/50000 [==============================] - 33s 658us/step - loss: 0.1849 - acc: 0.9577 - val_loss: 0.1509 - val_acc: 0.9725\n",
      "Epoch 19/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1746 - acc: 0.9603Epoch 00019: val_loss did not improve\n",
      "50000/50000 [==============================] - 34s 677us/step - loss: 0.1746 - acc: 0.9603 - val_loss: 0.1452 - val_acc: 0.9739\n",
      "Epoch 20/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1940 - acc: 0.9575Epoch 00020: val_loss did not improve\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.1940 - acc: 0.9575 - val_loss: 0.1618 - val_acc: 0.9705\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "csv_logger = CSVLogger('Results_0.01_model600'+'.csv')\n",
    "model_checkpoint = ModelCheckpoint('Checkpoint_0.01_model600'+'.hdf5',monitor = 'val_loss',\n",
    "                                    verbose = 1, save_best_only = True)\n",
    "history = model2.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_iterations,\n",
    "                    verbose = 1, validation_data = (X_validation, Y_validation),callbacks=[csv_logger,model_checkpoint])\n",
    "score2 = model2.evaluate(X_validation, Y_validation, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(800, input_shape=(784,)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.3570 - acc: 0.8945Epoch 00001: val_loss improved from inf to 0.14343, saving model to Checkpoint_0.01_model800.hdf5\n",
      "50000/50000 [==============================] - 32s 638us/step - loss: 0.3566 - acc: 0.8946 - val_loss: 0.1434 - val_acc: 0.9582\n",
      "Epoch 2/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2574 - acc: 0.9253Epoch 00002: val_loss improved from 0.14343 to 0.12784, saving model to Checkpoint_0.01_model800.hdf5\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.2572 - acc: 0.9254 - val_loss: 0.1278 - val_acc: 0.9622\n",
      "Epoch 3/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2443 - acc: 0.9309Epoch 00003: val_loss improved from 0.12784 to 0.12541, saving model to Checkpoint_0.01_model800.hdf5\n",
      "50000/50000 [==============================] - 41s 823us/step - loss: 0.2442 - acc: 0.9309 - val_loss: 0.1254 - val_acc: 0.9660\n",
      "Epoch 4/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2267 - acc: 0.9374Epoch 00004: val_loss improved from 0.12541 to 0.11848, saving model to Checkpoint_0.01_model800.hdf5\n",
      "50000/50000 [==============================] - 41s 813us/step - loss: 0.2266 - acc: 0.9375 - val_loss: 0.1185 - val_acc: 0.9688\n",
      "Epoch 5/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2267 - acc: 0.9385- ETA: 2s - loEpoch 00005: val_loss did not improve\n",
      "50000/50000 [==============================] - 41s 826us/step - loss: 0.2270 - acc: 0.9385 - val_loss: 0.1256 - val_acc: 0.9686\n",
      "Epoch 6/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2206 - acc: 0.9412- ETA: 2s - loss: Epoch 00006: val_loss did not improve\n",
      "50000/50000 [==============================] - 42s 841us/step - loss: 0.2204 - acc: 0.9412 - val_loss: 0.1360 - val_acc: 0.9659\n",
      "Epoch 7/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2118 - acc: 0.9449Epoch 00007: val_loss did not improve\n",
      "50000/50000 [==============================] - 42s 839us/step - loss: 0.2119 - acc: 0.9449 - val_loss: 0.1268 - val_acc: 0.9708\n",
      "Epoch 8/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2026 - acc: 0.9468Epoch 00008: val_loss did not improve\n",
      "50000/50000 [==============================] - 42s 834us/step - loss: 0.2028 - acc: 0.9469 - val_loss: 0.1228 - val_acc: 0.9706\n",
      "Epoch 9/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9504Epoch 00009: val_loss did not improve\n",
      "50000/50000 [==============================] - 44s 885us/step - loss: 0.1987 - acc: 0.9503 - val_loss: 0.1387 - val_acc: 0.9701\n",
      "Epoch 10/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.2076 - acc: 0.9491- ETAEpoch 00010: val_loss did not improve\n",
      "50000/50000 [==============================] - 43s 867us/step - loss: 0.2076 - acc: 0.9491 - val_loss: 0.1360 - val_acc: 0.9701\n",
      "Epoch 11/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9524Epoch 00011: val_loss did not improve\n",
      "50000/50000 [==============================] - 44s 871us/step - loss: 0.1964 - acc: 0.9523 - val_loss: 0.1434 - val_acc: 0.9715\n",
      "Epoch 12/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1985 - acc: 0.9512Epoch 00012: val_loss did not improve\n",
      "50000/50000 [==============================] - 43s 853us/step - loss: 0.1983 - acc: 0.9513 - val_loss: 0.1336 - val_acc: 0.9726\n",
      "Epoch 13/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1991 - acc: 0.9524Epoch 00013: val_loss did not improve\n",
      "50000/50000 [==============================] - 43s 862us/step - loss: 0.1989 - acc: 0.9524 - val_loss: 0.1464 - val_acc: 0.9718\n",
      "Epoch 14/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1953 - acc: 0.9535Epoch 00014: val_loss did not improve\n",
      "50000/50000 [==============================] - 43s 851us/step - loss: 0.1951 - acc: 0.9535 - val_loss: 0.1446 - val_acc: 0.9712\n",
      "Epoch 15/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1881 - acc: 0.9566Epoch 00015: val_loss did not improve\n",
      "50000/50000 [==============================] - 43s 852us/step - loss: 0.1883 - acc: 0.9566 - val_loss: 0.1515 - val_acc: 0.9700\n",
      "Epoch 16/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9556Epoch 00016: val_loss did not improve\n",
      "50000/50000 [==============================] - 42s 849us/step - loss: 0.1833 - acc: 0.9556 - val_loss: 0.1360 - val_acc: 0.9718\n",
      "Epoch 17/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1849 - acc: 0.9572Epoch 00017: val_loss did not improve\n",
      "50000/50000 [==============================] - 43s 852us/step - loss: 0.1850 - acc: 0.9572 - val_loss: 0.1338 - val_acc: 0.9720\n",
      "Epoch 18/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1945 - acc: 0.9565Epoch 00018: val_loss did not improve\n",
      "50000/50000 [==============================] - 44s 880us/step - loss: 0.1944 - acc: 0.9565 - val_loss: 0.1435 - val_acc: 0.9722\n",
      "Epoch 19/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9573Epoch 00019: val_loss did not improve\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 0.1845 - acc: 0.9574 - val_loss: 0.1514 - val_acc: 0.9736\n",
      "Epoch 20/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1878 - acc: 0.9587Epoch 00020: val_loss did not improve\n",
      "50000/50000 [==============================] - 47s 935us/step - loss: 0.1876 - acc: 0.9588 - val_loss: 0.1604 - val_acc: 0.9707\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "csv_logger = CSVLogger('Results_0.01_model800'+'.csv')\n",
    "model_checkpoint = ModelCheckpoint('Checkpoint_0.01_model800'+'.hdf5',monitor = 'val_loss',\n",
    "                                    verbose = 1, save_best_only = True)\n",
    "history3 = model3.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_iterations,\n",
    "                    verbose = 1, validation_data = (X_validation, Y_validation),callbacks=[csv_logger,model_checkpoint])\n",
    "score3 = model3.evaluate(X_validation, Y_validation, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9692- ETA: 1s - lossEpoch 00001: val_loss improved from inf to 0.13362, saving model to Checkpoint_0.001_model256.hdf5\n",
      "50000/50000 [==============================] - 13s 250us/step - loss: 0.1227 - acc: 0.9692 - val_loss: 0.1336 - val_acc: 0.9752\n",
      "Epoch 2/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9745Epoch 00002: val_loss improved from 0.13362 to 0.13084, saving model to Checkpoint_0.001_model256.hdf5\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 0.1005 - acc: 0.9745 - val_loss: 0.1308 - val_acc: 0.9756\n",
      "Epoch 3/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9751Epoch 00003: val_loss improved from 0.13084 to 0.12866, saving model to Checkpoint_0.001_model256.hdf5\n",
      "50000/50000 [==============================] - 12s 247us/step - loss: 0.0938 - acc: 0.9751 - val_loss: 0.1287 - val_acc: 0.9760\n",
      "Epoch 4/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9773Epoch 00004: val_loss improved from 0.12866 to 0.12614, saving model to Checkpoint_0.001_model256.hdf5\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.0848 - acc: 0.9773 - val_loss: 0.1261 - val_acc: 0.9761\n",
      "Epoch 5/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9770Epoch 00005: val_loss did not improve\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 0.0811 - acc: 0.9769 - val_loss: 0.1264 - val_acc: 0.9768\n",
      "Epoch 6/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9788Epoch 00006: val_loss did not improve\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 0.0767 - acc: 0.9788 - val_loss: 0.1263 - val_acc: 0.9769\n",
      "Epoch 7/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9797Epoch 00007: val_loss improved from 0.12614 to 0.12509, saving model to Checkpoint_0.001_model256.hdf5\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.0738 - acc: 0.9797 - val_loss: 0.1251 - val_acc: 0.9760\n",
      "Epoch 8/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9803Epoch 00008: val_loss improved from 0.12509 to 0.12293, saving model to Checkpoint_0.001_model256.hdf5\n",
      "50000/50000 [==============================] - 12s 238us/step - loss: 0.0707 - acc: 0.9804 - val_loss: 0.1229 - val_acc: 0.9770\n",
      "Epoch 9/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9797Epoch 00009: val_loss did not improve\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 0.0691 - acc: 0.9796 - val_loss: 0.1238 - val_acc: 0.9763\n",
      "Epoch 10/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9801Epoch 00010: val_loss did not improve\n",
      "50000/50000 [==============================] - 12s 238us/step - loss: 0.0704 - acc: 0.9802 - val_loss: 0.1242 - val_acc: 0.9768\n",
      "Epoch 11/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9811Epoch 00011: val_loss did not improve\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 0.0630 - acc: 0.9810 - val_loss: 0.1251 - val_acc: 0.9765\n",
      "Epoch 12/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9822Epoch 00012: val_loss improved from 0.12293 to 0.12200, saving model to Checkpoint_0.001_model256.hdf5\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 0.0631 - acc: 0.9823 - val_loss: 0.1220 - val_acc: 0.9778\n",
      "Epoch 13/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9827Epoch 00013: val_loss did not improve\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 0.0602 - acc: 0.9827 - val_loss: 0.1240 - val_acc: 0.9767\n",
      "Epoch 14/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9823Epoch 00014: val_loss did not improve\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 0.0602 - acc: 0.9823 - val_loss: 0.1232 - val_acc: 0.9770\n",
      "Epoch 15/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9826Epoch 00015: val_loss did not improve\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 0.0587 - acc: 0.9826 - val_loss: 0.1254 - val_acc: 0.9764\n",
      "Epoch 16/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9826Epoch 00016: val_loss did not improve\n",
      "50000/50000 [==============================] - 13s 253us/step - loss: 0.0558 - acc: 0.9826 - val_loss: 0.1259 - val_acc: 0.9775\n",
      "Epoch 17/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9836Epoch 00017: val_loss did not improve\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 0.0563 - acc: 0.9835 - val_loss: 0.1251 - val_acc: 0.9778\n",
      "Epoch 18/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9835Epoch 00018: val_loss did not improve\n",
      "50000/50000 [==============================] - 13s 253us/step - loss: 0.0540 - acc: 0.9834 - val_loss: 0.1231 - val_acc: 0.9778\n",
      "Epoch 19/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9824Epoch 00019: val_loss did not improve\n",
      "50000/50000 [==============================] - 12s 247us/step - loss: 0.0578 - acc: 0.9824 - val_loss: 0.1255 - val_acc: 0.9771\n",
      "Epoch 20/20\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9831Epoch 00020: val_loss improved from 0.12200 to 0.12187, saving model to Checkpoint_0.001_model256.hdf5\n",
      "50000/50000 [==============================] - 12s 247us/step - loss: 0.0577 - acc: 0.9831 - val_loss: 0.1219 - val_acc: 0.9774\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "csv_logger = CSVLogger('Results_0.001_model256'+'.csv')\n",
    "model_checkpoint = ModelCheckpoint('Checkpoint_0.001_model256'+'.hdf5',monitor = 'val_loss',\n",
    "                                    verbose = 1, save_best_only = True)\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_iterations,\n",
    "                    verbose = 1, validation_data = (X_validation, Y_validation),callbacks=[csv_logger,model_checkpoint])\n",
    "score = model.evaluate(X_validation, Y_validation, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9672Epoch 00001: val_loss improved from inf to 0.12915, saving model to Checkpoint_0.001_model600.hdf5\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.1403 - acc: 0.9673 - val_loss: 0.1292 - val_acc: 0.9779\n",
      "Epoch 2/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9742Epoch 00002: val_loss improved from 0.12915 to 0.12606, saving model to Checkpoint_0.001_model600.hdf5\n",
      "50000/50000 [==============================] - 24s 479us/step - loss: 0.1071 - acc: 0.9742 - val_loss: 0.1261 - val_acc: 0.9787\n",
      "Epoch 3/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9773Epoch 00003: val_loss improved from 0.12606 to 0.12480, saving model to Checkpoint_0.001_model600.hdf5\n",
      "50000/50000 [==============================] - 24s 479us/step - loss: 0.0944 - acc: 0.9773 - val_loss: 0.1248 - val_acc: 0.9797\n",
      "Epoch 4/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9779Epoch 00004: val_loss improved from 0.12480 to 0.12393, saving model to Checkpoint_0.001_model600.hdf5\n",
      "50000/50000 [==============================] - 24s 486us/step - loss: 0.0853 - acc: 0.9779 - val_loss: 0.1239 - val_acc: 0.9797\n",
      "Epoch 5/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9796Epoch 00005: val_loss improved from 0.12393 to 0.12271, saving model to Checkpoint_0.001_model600.hdf5\n",
      "50000/50000 [==============================] - 25s 491us/step - loss: 0.0790 - acc: 0.9797 - val_loss: 0.1227 - val_acc: 0.9796\n",
      "Epoch 6/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9804Epoch 00006: val_loss did not improve\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 0.0783 - acc: 0.9804 - val_loss: 0.1260 - val_acc: 0.9788\n",
      "Epoch 7/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9812Epoch 00007: val_loss did not improve\n",
      "50000/50000 [==============================] - 24s 481us/step - loss: 0.0700 - acc: 0.9812 - val_loss: 0.1265 - val_acc: 0.9791\n",
      "Epoch 8/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9814Epoch 00008: val_loss did not improve\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 0.0703 - acc: 0.9814 - val_loss: 0.1267 - val_acc: 0.9788\n",
      "Epoch 9/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9825Epoch 00009: val_loss did not improve\n",
      "50000/50000 [==============================] - 25s 494us/step - loss: 0.0666 - acc: 0.9825 - val_loss: 0.1244 - val_acc: 0.9789\n",
      "Epoch 10/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9830Epoch 00010: val_loss did not improve\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 0.0653 - acc: 0.9829 - val_loss: 0.1282 - val_acc: 0.9788\n",
      "Epoch 11/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9830Epoch 00011: val_loss did not improve\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 0.0635 - acc: 0.9830 - val_loss: 0.1263 - val_acc: 0.9787\n",
      "Epoch 12/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9818Epoch 00012: val_loss did not improve\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 0.0659 - acc: 0.9818 - val_loss: 0.1248 - val_acc: 0.9790\n",
      "Epoch 13/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9839Epoch 00013: val_loss did not improve\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 0.0593 - acc: 0.9839 - val_loss: 0.1266 - val_acc: 0.9793\n",
      "Epoch 14/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9852Epoch 00014: val_loss did not improve\n",
      "50000/50000 [==============================] - 25s 499us/step - loss: 0.0540 - acc: 0.9852 - val_loss: 0.1255 - val_acc: 0.9802\n",
      "Epoch 15/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9841Epoch 00015: val_loss did not improve\n",
      "50000/50000 [==============================] - 26s 515us/step - loss: 0.0579 - acc: 0.9841 - val_loss: 0.1264 - val_acc: 0.9796\n",
      "Epoch 16/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9844Epoch 00016: val_loss did not improve\n",
      "50000/50000 [==============================] - 25s 502us/step - loss: 0.0583 - acc: 0.9845 - val_loss: 0.1235 - val_acc: 0.9797\n",
      "Epoch 17/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9856Epoch 00017: val_loss did not improve\n",
      "50000/50000 [==============================] - 25s 503us/step - loss: 0.0530 - acc: 0.9857 - val_loss: 0.1273 - val_acc: 0.9791\n",
      "Epoch 18/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9854Epoch 00018: val_loss did not improve\n",
      "50000/50000 [==============================] - 25s 500us/step - loss: 0.0530 - acc: 0.9854 - val_loss: 0.1296 - val_acc: 0.9786\n",
      "Epoch 19/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9866Epoch 00019: val_loss did not improve\n",
      "50000/50000 [==============================] - 26s 519us/step - loss: 0.0495 - acc: 0.9866 - val_loss: 0.1272 - val_acc: 0.9794\n",
      "Epoch 20/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9859Epoch 00020: val_loss did not improve\n",
      "50000/50000 [==============================] - 25s 505us/step - loss: 0.0511 - acc: 0.9859 - val_loss: 0.1245 - val_acc: 0.9799\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "csv_logger = CSVLogger('Results_0.001_model600'+'.csv')\n",
    "model_checkpoint = ModelCheckpoint('Checkpoint_0.001_model600'+'.hdf5',monitor = 'val_loss',\n",
    "                                    verbose = 1, save_best_only = True)\n",
    "history = model2.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_iterations,\n",
    "                    verbose = 1, validation_data = (X_validation, Y_validation),callbacks=[csv_logger,model_checkpoint])\n",
    "score2 = model2.evaluate(X_validation, Y_validation, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9694Epoch 00001: val_loss improved from inf to 0.13390, saving model to Checkpoint_0.001_model800.hdf5\n",
      "50000/50000 [==============================] - 31s 619us/step - loss: 0.1390 - acc: 0.9694 - val_loss: 0.1339 - val_acc: 0.9771\n",
      "Epoch 2/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9751Epoch 00002: val_loss improved from 0.13390 to 0.13041, saving model to Checkpoint_0.001_model800.hdf5\n",
      "50000/50000 [==============================] - 31s 621us/step - loss: 0.1032 - acc: 0.9751 - val_loss: 0.1304 - val_acc: 0.9775\n",
      "Epoch 3/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9769Epoch 00003: val_loss improved from 0.13041 to 0.12830, saving model to Checkpoint_0.001_model800.hdf5\n",
      "50000/50000 [==============================] - 31s 623us/step - loss: 0.0957 - acc: 0.9769 - val_loss: 0.1283 - val_acc: 0.9783\n",
      "Epoch 4/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9788Epoch 00004: val_loss improved from 0.12830 to 0.12559, saving model to Checkpoint_0.001_model800.hdf5\n",
      "50000/50000 [==============================] - 32s 635us/step - loss: 0.0835 - acc: 0.9788 - val_loss: 0.1256 - val_acc: 0.9778\n",
      "Epoch 5/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9794Epoch 00005: val_loss improved from 0.12559 to 0.12122, saving model to Checkpoint_0.001_model800.hdf5\n",
      "50000/50000 [==============================] - 32s 638us/step - loss: 0.0804 - acc: 0.9794 - val_loss: 0.1212 - val_acc: 0.9784\n",
      "Epoch 6/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9800Epoch 00006: val_loss improved from 0.12122 to 0.11984, saving model to Checkpoint_0.001_model800.hdf5\n",
      "50000/50000 [==============================] - 33s 651us/step - loss: 0.0780 - acc: 0.9801 - val_loss: 0.1198 - val_acc: 0.9785\n",
      "Epoch 7/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9816Epoch 00007: val_loss did not improve\n",
      "50000/50000 [==============================] - 33s 655us/step - loss: 0.0721 - acc: 0.9816 - val_loss: 0.1200 - val_acc: 0.9796\n",
      "Epoch 8/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9814Epoch 00008: val_loss improved from 0.11984 to 0.11862, saving model to Checkpoint_0.001_model800.hdf5\n",
      "50000/50000 [==============================] - 32s 647us/step - loss: 0.0722 - acc: 0.9813 - val_loss: 0.1186 - val_acc: 0.9792\n",
      "Epoch 9/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9834Epoch 00009: val_loss did not improve\n",
      "50000/50000 [==============================] - 32s 638us/step - loss: 0.0621 - acc: 0.9834 - val_loss: 0.1218 - val_acc: 0.9785\n",
      "Epoch 10/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9835Epoch 00010: val_loss improved from 0.11862 to 0.11850, saving model to Checkpoint_0.001_model800.hdf5\n",
      "50000/50000 [==============================] - 32s 648us/step - loss: 0.0645 - acc: 0.9834 - val_loss: 0.1185 - val_acc: 0.9791\n",
      "Epoch 11/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9837Epoch 00011: val_loss did not improve\n",
      "50000/50000 [==============================] - 33s 656us/step - loss: 0.0623 - acc: 0.9837 - val_loss: 0.1209 - val_acc: 0.9792\n",
      "Epoch 12/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9839Epoch 00012: val_loss did not improve\n",
      "50000/50000 [==============================] - 33s 658us/step - loss: 0.0605 - acc: 0.9839 - val_loss: 0.1203 - val_acc: 0.9792\n",
      "Epoch 13/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9837Epoch 00013: val_loss did not improve\n",
      "50000/50000 [==============================] - 33s 656us/step - loss: 0.0598 - acc: 0.9837 - val_loss: 0.1187 - val_acc: 0.9787\n",
      "Epoch 14/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9844Epoch 00014: val_loss improved from 0.11850 to 0.11782, saving model to Checkpoint_0.001_model800.hdf5\n",
      "50000/50000 [==============================] - 34s 674us/step - loss: 0.0577 - acc: 0.9843 - val_loss: 0.1178 - val_acc: 0.9796\n",
      "Epoch 15/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9847Epoch 00015: val_loss did not improve\n",
      "50000/50000 [==============================] - 34s 677us/step - loss: 0.0536 - acc: 0.9847 - val_loss: 0.1185 - val_acc: 0.9798\n",
      "Epoch 16/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9845Epoch 00016: val_loss did not improve\n",
      "50000/50000 [==============================] - 32s 650us/step - loss: 0.0561 - acc: 0.9845 - val_loss: 0.1182 - val_acc: 0.9786\n",
      "Epoch 17/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9859Epoch 00017: val_loss did not improve\n",
      "50000/50000 [==============================] - 32s 637us/step - loss: 0.0548 - acc: 0.9859 - val_loss: 0.1181 - val_acc: 0.9791\n",
      "Epoch 18/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9866Epoch 00018: val_loss improved from 0.11782 to 0.11697, saving model to Checkpoint_0.001_model800.hdf5\n",
      "50000/50000 [==============================] - 32s 642us/step - loss: 0.0501 - acc: 0.9866 - val_loss: 0.1170 - val_acc: 0.9800\n",
      "Epoch 19/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9866Epoch 00019: val_loss did not improve\n",
      "50000/50000 [==============================] - 32s 644us/step - loss: 0.0491 - acc: 0.9865 - val_loss: 0.1219 - val_acc: 0.9798\n",
      "Epoch 20/20\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9868Epoch 00020: val_loss did not improve\n",
      "50000/50000 [==============================] - 32s 639us/step - loss: 0.0495 - acc: 0.9868 - val_loss: 0.1210 - val_acc: 0.9784\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "csv_logger = CSVLogger('Results_0.001_model800'+'.csv')\n",
    "model_checkpoint = ModelCheckpoint('Checkpoint_0.001_model800'+'.hdf5',monitor = 'val_loss',\n",
    "                                    verbose = 1, save_best_only = True)\n",
    "history = model3.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_iterations,\n",
    "                    verbose = 1, validation_data = (X_validation, Y_validation),callbacks=[csv_logger,model_checkpoint])\n",
    "score3 = model3.evaluate(X_validation, Y_validation, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = pd.read_csv('Results_0.01_model256.csv')\n",
    "lr2 = pd.read_csv('Results_0.001_model256.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "res256 = pd.read_csv('Results_0.01_model256.csv')\n",
    "res600 = pd.read_csv('Results_0.01_model600.csv')\n",
    "res800 = pd.read_csv('Results_0.01_model800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEZCAYAAABSN8jfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmczfX3wPHXUUqyk+xLKkSpiPpJTaG0fFsoqXwt7SX1\nbfOV6otKpYU2bZIU7Yg2yjIlZclazCBZsmbfjVnO74/3Z8Y17ow7c+/n3jsz5/l4zMO9n/Xca+ae\n+95FVTHGGGPCUSzWARhjjCn4LJkYY4wJmyUTY4wxYbNkYowxJmyWTIwxxoTNkokxxpiwWTIxhZqI\n7BKROj5ct6+IfBjp64Z47zdF5LFY3NuYnFgyMVEjIhNEpF+Q7VeLyHoRifjvo6qWVtWVkb5u5uV9\num7uN1W9W1UHxOLe2YnIcBF5MtZxmNizZGKi6X3g30G2dwY+VNWMvFxMRI6KRFDxJJ5eUzzFYuKf\nJRMTTV8CFUTk/MwNIlIOuBL4wHt+uYjMFZEdIrJKRPoGHFtbRDJE5BYRWQVMFpGvReTewJuIyAIR\nucp7nCEiJ3mPh4vI6945O0XkVxGpG3DeJSKSLCLbRGSIiCSKyC2hvDAROVdEpnvnzhORCwP2dROR\nxd49/xSROwL2XSgif4tILxFZD7wXsO1BEdkoImtFpFvAOVmlgRCOrSAiX3nv50wReUpEpuXwGg57\nf73tn3klx23ee9LQ2347cDPQy3tt47ztVUXkCxH5R0SWi0jPgHucIyKzvXjWi8iLoby/Jv5ZMjFR\no6r7gc+BLgGbbwCSVPUP7/lu4N+qWha4ArgrMzEEuACoD1wKjMCVbAAQkSZANeCbzNtmO7cT0Bco\nBywHBnjnVfRi+y9QEVgCnBfK6xKR6sDXwJOqWh54GBjtXRNgI3C5qpYBugODReTMgEtU8eKpBdwR\nsK2091puA4aISNkcQsjt2DeAXUBloBvQNch7kt0FQAPc+wvwLVDPu8Zc4CMAVR0KjAKeV9Uyqnq1\niAjwFTAPqAq0Bu4XkbbetV4BXvb+f+sBnx0hFlNAWDIx0TYC6Cgix3rP/+1tA0BVf1LVRd7jP4BP\ngAsDzlegr6ruV9UUYBxwsojU8/Z3Bj5V1XTvuWS7/xhVneNVqY0CMj/ULwf+UNVxqpqhqq/ikkAo\nbga+UdWJXtyTgd+8a6Kq32W226jqNOB7oFXA+enea0r1XhPAAeApVU1X1e9wSbZ+DvcPeqzXBtUe\n+J+qpqhqEgHvdQ4y3999mbGo6vuquldVU4EngSYiUjqH888BKqnqAC+elcC7uCQOkIr7/6roXXPW\nEeIxBYQlExNVqjod+Ae42qtiaob3TRdARJqLyBSvimQ7cCdQKdtl1gRc7wDu221n71vxjUBuvaw2\nBDzeC5TyHlcD/s7pPkdQG5cgt3o/24CWuG/miMhlXpXaFm/fZdle0ybvgzrQlmxtSIGxZpfTsScA\nR2V7HdlfYzBZx4tIMRF5zque2w6swCWc7P8nmWoD1bO9F4/iSjUAt+CSYrJX7XZFCPGYAuDoWAdg\niqQPcdUtDYDvVXVTwL6PgFeBS1U1VUQG46qdAmWvpvnAu+Z0YI+qzsxHTOuB7NVpNUI892/gA1W9\nM/sOETkG+AJXYhqnqhkiMpZDS0x+9QrbBKThXsef3raaIZwXGM9NwL+Ai1V1tVd9to2D8WeP/W/g\nL1UNWopS1eXeNRGRDsAXIlJBVfeFEJeJY1YyMbHwAdAGV7+fvdqlFLDNSyTN8T54AmSvtkJVZwAZ\nwEvkXirJzTdAYxG5SkSO8hr1Twzx3JHAv7wG/GIiUsJrGK8GHOP9bPYSyWXAJfmMMU+80soYoJ+I\nHCciDTi0vSqY7O9vaSAF2CYixwPPcmgC2QicFPB8FrDT61BQwnsvG4lIMwARuVlEMks1O7xrpWMK\nPEsmJupUdRXwC1ASGJ9t9z3AUyKyA3gc+DT76Tlc9gOgMe6DPZTjs8e0BbgeeAHYjCs1/Yb7ID3S\nuWuAq4E+uNLAKlwjfDFV3Q3cB3wuIltxbQfjQokp+23yeWxPXOP+elzi/ojcX1OwUt9qYC3wB+7/\nLdAwoJFXpTXGS2D/wrVFrcBVaQ4FynjHtwMWichOYDBwg1dVaQo48XtxLBFpB7yMS1zDVHVgtv21\ngPdw9btbgM6qus7bNxDXo0eAH1T1P972s3FjFkoA32ZuN0WXiPwbuF1VL4jQ9QTXdnCTqv4YiWvG\nAxF5DjhRVbvHOhZTuPhaMvF6k7yO62LYCLjRK2oHehF4X1Wb4HqKPOedex7wf6raGPeNs7mIZH5Q\nvAncpqqnAqeKyKWYIktESuJKNG+HeZ1LRKSs19Msc7qSGeHGF0siUl9ETvceNwduxVV9GRNRfldz\nNQeWqeoqr7fKJ7jqgECnAVMAVDUxYL8CJUSkBHAcrrPARhGpApQO6FL4AXCNr6/CxC0RuQRXlbIe\n+DjMy52HG3vyD65EfHVAV92CqjQwRkR24/7+XlDVr2IckymE/O7NVZ1DuyKuwSWYQPOBDsBrItIe\nKCUi5VV1hogk4j4kAF5X1SUi0pRDuzqu8e5jiiBV/Z6cu8zm9Vr9gf6RuFa8UNXfgFNiHYcp/Pwu\nmRzW84bDG/geARJEZA5uINdaIM0bhNYA1/+/OtBa3DQcoVzTGGNMFPldMlmDmyIiUw1gXeABqroe\nVzLB63rYQVV3icidwIzM/uci8h1wLq63Ts3crplJRCzJGGNMPqhqsC/uOfK7ZDIbN3VCbW/wViey\ndQUVkYpezxlwI2Xf8x6vBi70+qkXx02psVhVN+D6sTf3zutCLl0tVdV+IvTTt2/fmMdQWH7svbT3\nM55/8sPXZKJufqR7cXMRLQI+UdUkEekvIld6hyUAS0QkGTflQuY6DV8AfwG/4yaNm6eq33r77sH1\nb1+Ka+Cf4OfrMMYYkzvfp1PxPujrZ9vWN+DxaGB0kPMygLtyuOYc4PTIRmqMMSa/bAS8CVlCQkKs\nQyg07L2MLHs/Y8/3EfCxJCJamF+fMcb4QUTQPDbA26zBxpi4V6dOHVatWhXrMAqd2rVrs3Llyohc\ny0omxpi4531TjnUYhU5O72t+SibWZmKMMSZslkyMMcaEzZKJMcaYsFkyMcaYMNWtW5cpU6bEOoyY\nsmRijDE+Gzx4MFWrVqV8+fLcdtttpKam5njs5MmTadiwIaVKlaJ169asXr06a9/nn39Oy5YtOf74\n47n44oujEXrILJkYY4xP0tPTmThxIs8//zxTp05l5cqVLF++nL59+wY9fsuWLXTo0IEBAwawdetW\nmjZtyg033JC1v2LFijzwwAM8+uij0XoJIbOuwcaYuBfvXYPr1q3LsGHDmDZtGn/88QclSpTgq6++\nYtCgQUyePJm6devy9NNPAzBlyhRuvvlm1q9ff9h1hg4dyogRI/j5558B2Lt3L5UqVWL+/Pmceuqp\nWccNGzaMUaNGhV21Zl2DjTEmTo0fP56OHTuyfft2brrpJhYtWkSTJk2y9jdp0oR//vmHbdu2HXZu\n9mNLlixJvXr1WLRoUVRiD4clE2NM4SAS/k8EnHfeefzrX/8CoESJEuzevZuyZctm7S9btiyqyq5d\nuw47N/uxmccHOzbe2HQqxpjCIU6qwWrWrHnI81KlSrFz586s5zt37kREKF269GHnZj828/hgx8Yb\nK5kYUwBt3ruZLXu3xDoME4RkK+E0atSIBQsWZD2fP38+J554IuXLlz/s3EaNGjF//vys53v27GH5\n8uU0atTIv4AjxJKJMQWIqjJq4ShOG3Ia9V+vz+BfB5OannM3UxN7Xbp0YdiwYSQlJbFt2zYGDBhA\n9+7dgx577bXXsmjRIsaOHUtKSgpPPvkkTZo0yWp8z8jIICUlhdTUVNLT00lJSSEtLS2aLydHlkyM\nKSC27ttKp9GdGDBtABM6T2Ba92lMWD6BJm814YflP8Q6vCIte2kk0KWXXkqvXr246KKLqFu3LnXr\n1qVfv35Z+xs3bszHH38MQKVKlRg9ejR9+vShQoUKzJ49m08++STr2A8//JDjjjuOHj168PPPP1Oy\nZEnuuOMO315XXljXYGMKgIl/TuTW8bdy/WnX80zrZziu+HGAK6mMXzKeByY+wJlVzuSlS16ibvm6\nMY428uK9a3BBFcmuwZZMjIlje1P30uuHXoxfMp7hVw+n9Umtgx63P20/L/3yEoNmDKLHOT3ofX5v\nShYvGeVo/WPJxB82zsSYImDW2lmc9fZZ7EjZwcK7F+aYSABKHF2Cxy54jPl3zmfplqU0HNKQzxd9\nbh/AJmqsZGJMnElNT2XAtAG8+dubvH7Z61zf6Po8X+PHlT9y34T7qHBcBV5t9yqnn3i6D5FGj5VM\n/GHVXCGyZFK4pKankqEZHHv0sbEOxTdLNi+h89jOVDyuIu9d/R7VSlfL97XSMtJ4Z8479Evsxw2N\nbqD/Rf2pcFyFiMWanpHOjpQdEb1mMKpKsWLFLJn4wJJJiCyZ5F9aRhq7Unax68AudqbsJD0jnTNO\nPCPXXit+xjJi/gj6/diPPQf20LFRR7o26cq5Nc6NSTx+UFWGzB5Cv8R+PHXRU9zV7K6IvbYte7fw\nxNQnGJ00micTnuS2s2/jqGJHhXx+SloKS7csJWlzEkmbkty/m5NYtmUZIkL9ivVp37A97Ru2p2Gl\nhhH9P0nenMx/JvyHif+eaMnEB5ZMQmTJBDI0g59X/8yKbSuyEkPmT+DzXSm7DtmekpZCqWNKUebY\nMpQ5tgz70vZR+pjS9GnVhw4NO+Tpwyi/VJWxyWN5bMpjVD6+Ms+1fo4aZWowcuFI3l/wPgDdmnTj\n303+TY0yNXyPB2Dj7o3MWT+HGmVqcGrFUylxdImwr7l251puGX8L2/dv58NrP+TUiqce+aR8mL9h\nPvd9dx+7D+zmtcteo2Wtlofs37F/B8mbkw9LGn/v+Js65erQ8ISGNKzk/ZzQkAaVGlDi6BJMXz2d\nMUljGJM8hpLFS9K+gUsszao1y3di2Zmykyd/fJIRC0bwWKvHeOC8ByyZ+MCSSYiKcjL5c+ufjJg/\ngg8WfkD5EuVpUqUJpY8pnZUcDnl87OHbSxYvecgHgaryzbJvGDBtANv2baP3+b25+fSbKX5UcV/i\nn7piKr0n9yYlLYVnWz9Lu5PbHRbPzLUzeX/++3y++HOaVm1K1yZdubbhtRHtxbT7wG5+WvUTk/6a\nxKS/JvH3zr9pWrUpa3etZcW2FdQoU+OwD9mGlRpStkTZI18c+PSPT7lvwn30OKcHfVr14ehi/s5w\npKp88scn9JrUi5Y1W3JCyROyksaO/TuoX6n+Ya+lXoV6HHPUMSFd+7d1vzEmaQyjk0azP20/1za4\nlvYN23N+rfND+gKSoRl8sOAD+kzuw2UnX8YzrZ/hxFInWpuJTyyZhKioJZMd+3fw2aLPGLFgBH9u\n/ZObTr+Jrk260qRKkyOfHCJVZerKqQyYNoDlW5fTq2Uvbjnrloh8QweYt34ej05+lGVbl/HURU/R\nqXEniknunQ73pe5j/JLxvL/gfWaumUmHhh3oemZXWtZsmedvxmkZacxeO9sljxWTmLt+Ls2qNaNN\n3Ta0OakNTas1zfrAT01PZfm25Yd8i0/alETy5mTKHFsmaJKpUqoKIsK2fdvo8W0P5q6fy8j2I2lW\nrVm+37P82H1gN2/99hZHyVFZsdUsW/OI73WoVJXFmxZnlVjW7lzL1fWvpn3D9lxc9+Kg7V6z186m\n53c9AXj1sldpXr151j5LJv6wZBKiopBM0jPSmbxiMiMWjOCbpd/Q5qQ2dG3SlXYnt/Ot1JBpxpoZ\nDJg2gDnr5vDgeQ9yZ9M7KX1s/iak+3Prnzwx9QkSVybyeKvHub3p7SF9G85u3a51rhps/vukZqTS\n5YwudGnShdrlagc9XlVZsmVJVskjcWUitcvVpu1JbWlzUhta1WrF8cccn6cYMjSDNTvXHEwyAckm\nLSONBpUasGbnGq5tcC3PtXmuUI0HycmKbSsYmzyWMUljWLRpEZefcjntG7Sn3cnt2H1gN30m9+G7\nP7/j2dbP8u8m/z4sqcV7MslczyTeVj88kkgmE1S10P64l1c4JW1K0t4/9NbqL1XXZu8009dmvqab\n92yOSSzz18/Xjp931ErPV9J+U/vplr1bQj533c51evfXd2vFgRX1qR+f0l0puyISU0ZGhs5aM0vv\n+foerTiwol70/kU6Yv4I3Z2yWzfs2qAjF4zUbl920xqDamjNQTW1+5fd9aOFH+mGXRsicv+cbNqz\nSX9a+ZPOWjPL1/vEs3U71+mbs9/Uth+01dLPlNYKAyvoQxMf0u37tud4Trz/LdepU0cnT56c4/5B\ngwZplSpVtFy5cnrrrbfqgQMHcjx20qRJ2qBBAz3++OP14osv1lWrVmXtS0lJ0e7du2uZMmW0atWq\nOmjQoKx9Bw4c0Ouuu07r1KmjIqI//vjjEePO6X31tuft8zavJxSkn3j/BcyrrXu36puz39QWQ1to\n1Rer6iPfP6J/bPwj1mFlSd6UrN2/7K4VBlbQXt/3yvWDefu+7dpnUh+tMLCCPjjhQd20Z5Nvce1P\n3a+fL/pcrxh1hZZ6ppSWe66cXvPJNTpk1hBdsnmJZmRk+HZvk7ste7fo6u2rj3hcvP8t55RM0tLS\ndMKECVqlShVNSkrS7du3a0JCgj766KNBr7N582YtW7asjh49WlNSUvSRRx7Rc889N2t/79699YIL\nLtAdO3ZoUlKSVqlSRSdOnKiqLpm88sorOn36dK1WrZolk0j+xPsv4JGkZ6Trjv079Nul32rHzztq\n2WfLasfPO+q3S7/V1PTUWIeXo5XbVmqPb3po+efK673f3Kurth/8ZrX3wF59YfoLesLzJ2j3L7sf\nsi8atu3bFtfvnQku3v+WM5NJv3799LrrrtPOnTtr2bJlddiwYXrTTTfpY489lnXs5MmTtUqVKkGv\n884772jLli2znu/Zs0ePO+44XbJkiaqqVq9eXSdNmpS1/4knntAbb7zxsOvUqFEj6snEFsfy0Z4D\ne1iyZQk79u84rDtuVlfcA4d3y83cvyd1D8cXP55GlRvRtUlX3rriLcofd/gaCPGmdrnavH756zx+\nweMM+nUQZ751Jtc0uIamVZvy3PTnaFatGVO7TqVR5eiv0VCuRLmo39MULePHj+eLL77gww8/ZP/+\n/bz66qtcc801WfsDl+3NvqZJbsv2Vq5cmXXr1nHGGWcccq1x48b5/6JCYMkkQtIz0lm8aTEz185k\n1tpZzFw7kz+3/skpFU6h/HHlg3bLrVKqStBuuZnddUsdUypivWtioUqpKjzf9nl6n9+bV2e+yvd/\nfc9n133GeTXPi3VophCS/uEPltS+4Tfy52XZ3uzJZPfu3VSuXPmQbZnL9u7evRsROexa8bKkryWT\nfFqzcw0z1xxMHHPXz6Vq6aq0qN6C5tWbc/vZt9OkSpN89UgqbCocV4F+Cf1iHYYp5CKRCCLBr2V7\nS5Uqhaqyc+dOKlWqdMi+eGDJJAQ7U3by27rfshLHrLWzSE1PpUWNFjSv1pw+rfpwTrVzCkQVlDHG\nXzkt23vdddcBR162d8SIEVnPM5ftbdy4MeXKlaNq1aosWLCA1q3dDNILFiyImyV9LZlkk5aRxu8b\nfz8kcazcvpImVZrQonoLOjXqxKBLBlGnXJ1CMy+UMcY/Xbp0oXv37tx0001UqVLliMv29urVi7Fj\nx3L55ZdnLdt7yimnZF3r6aefpmnTpmzYsIGhQ4ceknwOHDhARkYGACkpKaSkpHDssdGZGLVIJxNV\nZdWOVS5xrJnJrHWzmLd+HrXK1soqddzb/F5Or3y67wMAjTEFV6jL9u7fv5/rrrvusGV7H3vsMW68\n8casZXt79OhB586dadGixSHL9vbv35+7776b2rVrU7JkSXr37k3btm2z9tevX5/Vq1cD0K5dOwBW\nrFhBrVq1IvyKD+f7CHgRaQe8jFuIa5iqDsy2vxbwHnACsAXorKrrRCQBGAwoIEAD4AZVHS8iw4EL\ngR3e/m6qujDIvTXw9W3fv53Za2cf0kheTIpltXO0qN6CZtWahTyvkjEmOuJ9BHxBVWCmUxGRYsBS\noDWwDpgNdFLV5IBjPgPGq+pIL4Hcoqpdsl2nPLAMqK6qKV4yGa+qY49wf3195uvMWudKHmt3reXs\nqmfTvFpzWtRoQYvqLahRpoZVVxkT5yyZ+COSycTvaq7mwDJVXQUgIp8AVwPJAcecBvwHQFUTRSRY\np+nrgO9UNSVgW0h9ZudtmMf5Nc/nwXMfpFHlRr7PymqMMUWR35+s1YG/A56vwSWYQPOBDsBrItIe\nKCUi5VV1W8AxnYCXsp33tIg8AUwGeqtqarAA3r3q3XDiN8YYEwK/k0mwYlL2MtUjwOsi0g34CVgL\npGVdQKQK0BiYGHBOb1XdKCLFgaHAf4GngwUQ2NCVkJBAQkJCXl+DMcYUaomJiSQmJoZ1Db/bTM4F\n+qlqO+95b9ycLwNzOP54IElVawVsuw84TVXvyuGcC4GHVPWqIPvU6lmNKfiszcQfkWwz8XuujtnA\nySJSW0SOwVVXjQ88QEQqysEW8EdxPbsC3Qh8nO2cKt6/AlwD/OFD7MYYY0LkazWXqqaLyL3A9xzs\nGpwkIv2B2ar6NZAAPCsiGbhqrh6Z54tIbaCGqv6Y7dKjRKQSrhptPhC01GKMKRxq165tvS59ULt2\n8EXj8sNWWjTGGHOIeKzmMsYYUwRYMjHGGBM2SybGGGPCZsnEGGNM2CyZGGOMCZslE2OMMWGzZGKM\nMSZslkyMMcaEzZKJMcaYsFkyMcYUbGlpYDNdxJwlE2NMwaUK114L3bpZQokxSybGmILryy9h+XL4\n/Xd4Kfv6eSaabKJHY0zBtGcPnHYajBgBJ50ELVrA8OHQrl2sIyvw8jPRoyUTY0zB9OijsHo1jBrl\nnk+bBh06wM8/w6mnxja2As6XZCIijVW1QC4+ZcnEmEIqORlatYKFC6Fq1YPb33kHBg2CmTOhbNnY\nxVfA+ZVMfgaOAd4HPlLV7fmOMMosmRhTCKlCmzZw1VVw//2H7+/RA1auhPHj4aijoh5eYeDLeiaq\nej5wM1AT+E1EPhKRtvmM0RhjwvPpp7B5s0sawbz8smtPefzx6MZVxIXcZiIiR+HWW38V2IlbMreP\nqo7xL7zwWMnEmEJm505o2BA++wxatsz5uE2boHlzeOYZuPHG6MVXSPhVzXUG0B24AvgBt477XBGp\nBvyqqpFbRDjCLJkYU8g89BBs3ep6bR3JggWuOmzCBGja1P/Ytm+HcuX8v08U+LVs7+vAXKCJqvZQ\n1bkAqroOsHKkMSY6fv8dPvwQBg4M7fgmTeCtt9ygxo0b/Ytr+3bo3BmqVIG5c/27T5wLJZlcjmt4\n3wcgIsVEpCSAqn7oZ3DGGAO4RvcePaB/f6hcOfTzOnRwo+M7dICUlMjHNWUKnHGG6zn21lvuPlu2\nRP4+BUAoyWQScFzA85LeNmOMiY4PP4R9++COO/J+br9+cMIJcO+9kZtyZd8+eOAB6NIFhg6FIUNc\n0mrfHm6+GdLTI3OfAiSUZFJCVXdnPvEel/QvJGOMCbB9O/z3v/DGG/nr6lusGHzwAfz6q/vQD9fc\nua4NZu1a1y5z6aUH9z33nEs0Tz4Z/n0KmFCSyR4ROTvziYg0Bfb5F5IxxgR4/HE3puScc/J/jdKl\n3biTp56CqVPzd420NBgwwE3X8thjrotyxYqHHlO8uNs+bBh8/XX+4y2AQunNdQ7wCbDO21QVuEFV\n5/gcW9isN5cxBdzcuXDZZbB48eEf3PkxebKrhvr1V6hbN/Tz/vzTVWkddxy8/z7UrJn78dOnu4b/\nX3+FevXCCjkWfJubS0SKA/VxY0uSVTU1fyFGlyUTY3ymCpKnz5zQZWTA//0f3H473Hpr5K776qvw\n7rvwyy9QqlTux6q6NpHHHnMlpJ49XbVZKF57zZVQfvkFShaslgE/k0lj4DSgROY2Vf0gzxFGmSUT\nY3z0889w3XXw9NPuwz7SSeXdd+G999x9Qv0AD4Uq3HYbbNsGX3yR87U3bHDHrV/vOgCcdlre79O5\ns2vnGTHCv6TrA1/GmYhIX+A17+ci4HngqnxFaIwpHFavho4d4X//c43aV18d2bEcW7a40sAbb0Q2\nkYD7UH/jDZcsnnoq+DFjxsCZZ8JZZ7mqqrwmksz7vPMOzJvnug0Xdqqa6w/wOy7pLPCenwj8cKTz\n4uHHvTxjTETt2aN61lmqL77onqekqD76qGqVKqpjx0bmHrffrtqzZ2SulZP161Vr1FAdPfrgtu3b\nVbt2VT35ZNVffonMfZYuVT3hBNVff43M9aLA++zM0+dtKA3ws1S1uYjMwZVMdgFJqtrAvxQXGVbN\nZUyEqbq5ro455vCqm+nTXSP1hRe6yRbLlMnfPWbOdI3Xixf7Pz3Jb7+5Bv4pU9w0LV27ut5aL754\n5PaUvBg3zo1zmTMnb4MuY8Sv6VR+E5FywFBgDm5qlV/zEZ8xpqB77jn46y94++3D2wBatoT58+Ho\no91UJj/9lPfrp6fDPfe4KVOiMc9Vs2Yu8V10Edx0k6uye+utyCYScNWAXbpAp06ui3EhlGvJREQE\nqKGqf3vP6wBlVHVhVKILk5VMjImgr76Cu+92JYfq1Y987B13uA/QJ5+EY48N7R5DhrgZgRMTo9tg\nPX686zlWqZJ/90hPd6Wes88OfX6xGPFr1uDfVfX0sCKLEUsmxkRIUpKrvho/Hs49N7RzNm1yCeWv\nv1xvqDPOyP34f/6BRo3coMLGjcOPOR5t3uxGzw8a5ObxiqTFi+HZZ92ULtdeG9al/KrmmusNXDQm\ndjIyoHdvuOEGt2SriZ5t21w1zfPPh55IwM2HNWaMm8OqdWt44YXc56zq1cu1WRTWRAKu5PPFF3DX\nXZH7PZ4zxyWmiy5ya71cfHFkrptHoZRMkoGTgVXAHtzARVXVI3zNiD0rmRQS6elu4NrSpXDllfDS\nS+7DrV8/qFEj1tEVbmlpcMUVrmvs4MH5v87Kla7KC9w8WXXqHLr/559dw/7ixW7qk8Ju6FD3fs6a\nlf/2mWkm6jA3AAAgAElEQVTT3OJfv/8ODz/s/kaOPz4i4eWnZBJK99rawX5C7S4GtAOSgaXAf4Ps\nr4WbhXgBMAWo5m1PAObhGvzn4eYDu8rbVweYASwBPgaOzuHe4faQM7F24IBqp06qF1+sunu327Z1\nq2rv3qoVKqg+/LDqli2xjbEwe+gh1TZtVFNTw79WWprq88+rVqqkOny4akaG256aqnr66aqffhr+\nPQqKjAzVW25R7djx4PsQ6nkTJqi2aqV60kmq77yjun9/xMMjH12DQ0kGtYL9hHRxV432p5eAigPz\ngQbZjvkM6KwHE8gHQa5THtgMHOs9/xS43nv8JnBnDveP+Jtsomj/ftWrr1a9/HLVvXsP3792reqd\nd6pWrKg6YMDBZGMiY8QI1Xr1Ip+sFyxQPeMM1WuuUf3nH9VBg1zCysuHamGwd6/q2We7138k6emq\nY8aoNmumetppqiNHRibB58CvZPI7sND7dxmQBiwK6eJwLvBdwPPe2UsnwB+ZpRHv+Y4g17kd+DDg\n+SagWMA9JuRw/4i/ySZK9uxRvfRS1Q4d3KC43CxZ4r7hVa2q+sYbrjRjwjNzphto98cf/lx//37V\nXr3cQMeKFVWTk/25T7xbsUK1cmXVH38Mvj811SWORo1UmzZ1CSU93fewfEkmh50AZwPvhnhsB+Cd\ngOedgVezHTMS6Ok9bg+kA+WzHTMZuNx7XBFYGrCvBrAwh/tH+C02UbFzp2pCgurNN+ft29fs2apt\n27pv0x9/HJU/ukJp7VrV6tVVx43z/14//aQ6apT/94ln333nvgitXXtw2/79rgrrpJNcldaECVEt\nueUnmeR50ht1a8C3CPHwYA042VvEHwESvBH2rYC1uNKPu4BIFaAxMDEP1zQF1fbtcMklcPLJboT1\n0UeHfm6zZvD9925A3UsvuecTJ0Zudb2iYP9+17X0rrvcGiJ+a9XKDRYsytq1c+N3rr8eduyAV15x\nv/9jxrjp7n/6yS3AFecTRR7xL1VEHgx4WgxXMlmXw+HZrcG1sWSqkf1cVV2PK8EgIscDHVR1V8Ah\nHYGxqpruHb9ZRMqJSDFVzQh2zUD9+vXLepyQkEBCQkKIoZuo27zZJZJWrdyo5Pz+8bRu7XrJjB4N\n993nBtg9+yy0CPU7UBGl6pJIrVpukkUTPY895gaDVq3qpnf58ks3HiVKEhMTSUxMDOsaoXQN7hvw\nNA1YCYxW1f1HvLjIUbgeV62B9cAs4EZVTQo4piKwVVVVRJ4G0lS1X8D+X4HeqvpjwLZPgTGq+qmI\nvImbhPKwaTmta3ABsmEDtGkD//qX6+4YqW9haWkwfDj07++SyYABUL++W1p1507Ytcv9G/j4SNuO\nPtp17czPTLLx7OWX3Tfh6dMj1sXU5MGePW66+5NPjnUk/q1nEg4RaQe8givVDFPV50SkPzBbVb8W\nkQ7As0AG8BPQQ73Ft0SkNvCzqtbMds26uNUfy+O6DXfWIAt2WTIpIP7+25UmunRx39D8KM7v3Quv\nv+4G3m3f7pZXLVPGjWkoUyZvjxcudFOvjx0L550X+ViPZPduuOUWN+itTRto2xYuuCC8BPDDD+79\nnzEDateOXKymQPJrOpUfcN1wt3vPywOfqOql+Y40SiyZFAB//eUSSc+e8OCDRz4+XKned47ixcO7\nzoQJ7sN3+HA3qC9a1qxxpbemTV1CmTIFJk1ys982beoSS5s2rr0o1PamP/90kzR+/rlLSqbI8yuZ\nzFfVM7Ntm6eqZ+UjxqiyZBLnkpPdh1+fPq4BsqCZOROuucbNpNu1q//3mzfPNYr37AmPPHJoCW7P\nHtdQO2mS+1m1ChISDiaXU08NXuLbudNNkXLffa69xBj8SyZzgGtVdbX3vDauQfzsfEcaJZZM4tjC\nha4XyzPPQLdusY4m/5KT3eu4557DP+Ajafx4tzTuW2+FNkHgxo0webJLLD/84OJq08b9tG4NJ57o\n5ju75hqoVq1orARoQuZXMmkHvANkNoBfANyhqhNzPis+WDKJU7/95ubYeuUVN3FjQbd2rUsobdu6\nRZUivV75yy+7644dC82b5+8ay5a5pDJpkpvevVYtl0T27HHbjjkmcjGbAs+3BngRqYQbaS7Ar6q6\nOX8hRpclkzg0fbqbHnvoUDdZY2GxbZurgqpVy7WjROLDOS3NVT9NmwZffx25hvG0NDfT7IwZbozH\nCSdE5rqm0PCrZHItMEVVd3jPywEJqvplviONEksmcWbKFFcSGTnSDcIqbPbtcyvp7d/vxriEs1rf\nzp3QsaOrnvr00/wvgWtMPlgDfDaWTCIkJcWVJjZuDO86q1e7tRwuvDAyccWjtDTXmWDBAvjmm/x9\n61+1ylUDtmoFr76at1kAjImA/CSTUH5Lg1UA2293UfLRR3DgALzzTnjXqVrV1dMXZkcf7d6n//0P\nzj/fTeeSfe2O3Mya5RL3I4/A/ffH/RQaxmQKpWTyHrAdGIKbA6snbiLGbr5HFyYrmUSAqltudfBg\n1xPIhO6119xa399+e+Qla8GV2u6+G957z40lMSZG/Fq2tydwALeGyOfAfqBH3sMz+bJnj5v8LVZ+\n+MH1TmrdOnYxFFQ9e7q1vtu2hR9/zPk4VZd0HnjATVRpicQUQL5PpxJLBb5ksm+fW8+5fHn37TYW\n2rVzy6lGY1BeYTV5snsP337bVWEFOnDAlUbmzYOvvnKTUhoTY760mYjICUAvoBFQInO7qsZm1fqi\nIiMDund3XU1//dXVpednjEE4/vjDDS4cNy669y1sWrd2069ceSVs2gR33OG2b9vmBiCWKuVGr4fT\n+8uYGAulmmsUbg33ukB/3KzBs32MyQD07et6P40YAb17w1NPRT+GwYOhRw849tjo37uwOftslzAG\nDoQnn4Tly90kkWee6QYjWiIxBVxI06moalMRWaiqZ3jbZqvqOVGJMAwFtprrgw+gXz83qKxyZTdu\n4eST3ZQaZ0dpFpuNG6FhQzdyumLF6NyzKNiwwa1XsWwZvPBCwZyTzBR6fnUNzpzafb2IXIFbiKpC\nXoMzIfrpJ3j4YTflReXKbluJEtCrl/tG+2WUxoq+8YYbgGeJJLKqVHGN8cuXw1lxP1TLmJCFUjK5\nEpgG1AReA8oA/VV1vP/hhafAlUyWLXMD1UaOPLwb7r59UK+ea4g/88zg50fKvn1ubMS0aW62WWNM\nkRKXi2PFUoFKJlu2uDr0Rx6B228PfszgwW5uqy++8DeWd95xc0GNj/vvC8YYH1gyyabAJJMDB9xY\nhObNXT16TvbudaWT77+H00/3J5aMDGjUCN58062HYYwpcvwatGj8pOq6ilao4BZZyk3JkvDQQ/D0\n0/7F89137j6Fef4sY0zEWckk1p55BsaMcY2yoazhvXu3K51MnQqnnRb5eFq3dsvB3nxz5K9tjCkQ\n/Jo1+FigA1CHgN5fqvpkPmKMqrhPJp995npuzZiRtwkQn3vODSb86KPIxjN/vhtY99dftliSMUWY\nX12DxwE7gDlASn4CM0HMmAH33uvmvsrrTLo9erjSSXIyNGgQuZgGDXLzSVkiMcbkUSglkz9UtXGU\n4omouC2ZrFgBLVu61QavuCJ/1xgwAJYscQMcI2HtWteov3y5mwvMGFNk+dUA/4uI+NR1qAjascNV\nJfXunf9EAq5U8913bmxKJAwZAp07WyIxxuRLKCWTxcDJwApcNZcAmjm1SjyLu5JJaqpLIKee6ta6\nCHfho/79YeVKt+Z4OPbscYMUZ8xw1WfGmCLNrwb42sG2q+qqvNwoFuIqmai6eZhWr3aDASOxFOv2\n7W7Orlmz4KST8n+dIUPcNOljxoQfkzGmwPNt0KKINAFaeU+nqeqCfMQXdXGVTAYPdiWIn3+GMmUi\nd93//Q/Wr3ftL/mRnu4a8d9/37XjGGOKPF/aTETkftw09JW9n5Ei0jN/IRZR48bBiy+6KUoimUgA\n/vMfV6JYuTJ/53/9tRsw+X//F9GwjDFFSyjVXAuB81R1j/f8eOBXazMJ0dy5cOmlboLGc3yatf+x\nx9zcXm+9lfdzL7jAdTW+4YbIx2WMKZD86s0lQHrA83RvmzmSTZvg6qvdh7xfiQTc2uGffw5//523\n82bPhlWr3Gp/xhgThlCSyXBgpoj0E5F+wAxgmK9RFRZvvw2XXOL/h3WlSnDbbUee2yu7wYPh/vsj\n0xnAGFOkhdoAfzZwPq5E8pOqzvM7sEiIaTVXWhrUrQtffeX/+iMA//zjGtJ//x2qVz/y8atXu7hW\nrICyZf2PzxhTYES0mktEynj/VsCt+z4S+BBY5W0zufnqK6hVKzqJBNyqjLfcAs8/H9rxr70G3bpZ\nIjHGRESOJRMR+VpVrxSRFUDgQZmDFsMY2BAdMS2ZtGkD3btHd/bdDRvcTMKLFkHVqjkft2uXG6Q4\ndy7UDjqMyBhThNniWNnELJkkJ7uFpVatgmOPje69H3jAjawfNCjnY155BX75BT79NHpxGWMKDL9G\nwE9W1dZH2haPYpZM7r8fSpVykzFG27p10LgxJCXBiScevj8tDU45BT75BFq0iH58xpi4F+k2kxJe\n20glESkvIhW8nzpAHudML0J274aRI+HOO2Nz/2rVXNXaiy8G3//ll+4YSyTGmAjKrWvwnbg1TBp4\n/2b+jAOGhHoDEWknIskislRE/htkfy0RmSQiC0RkiohUC9hXU0QmishiEflDRGp524eLyF8iMk9E\n5opI/AygHDUKWrVyje+x8t//wrBhbpxLdoMGuaV/jTEmgkKp5uqpqq/l6+IixYClQGtgHTAb6KSq\nyQHHfAaMV9WRIpIA3KKqXbx9U4GnVHWKiJQEMlR1v4gM984Ze4T7R7eaS9X13nrxRWjbNnr3Deae\ne1xPrWefPbjt119dqWXZMjjqqNjFZoyJa76stKiqr4lIY+A0oETA9lBWZWoOLMucYVhEPgGuBpID\njjkN+I93zUQRGecd2xA4SlWnePv2Zrt2KAMuo2v6dNi3z62jHmu9e8NZZ7llgStWdNsGDXJzeVki\nMcZEWCgTPfYFXvN+LgKeB64K8frVgcA5PtZ42wLNx60xj4i0B0qJSHngVGCHiIwWkTkiMlDkkAVA\nnhaR+SLykogUDzEefw0Z4koExeIgz9Wq5UbeDx7snq9YAVOnuu7KxhgTYaF86l2Hq6baoKrdgSZA\nqCPdghWTstc7PQIkiMgc3DT3a4E0XKnpfOBB4BygHtDNO6e3qjb0tlcEDmuLiboNG9zKh926xTqS\ng/r0gTffhG3bXHfgW2+F0qVjHZUxphAKZVKmfaqaISJp3qj4f4CaIV5/DRDYEl0D13aSRVXXc7Bk\ncjzQQVV3icgaYF5AFdmXQAtguKpu9M5N9dpPcmxR7tevX9bjhIQEEhISQgw9j959F66/HsqV8+f6\n+VGnDlxzjVuR8YMPYOHCWEdkjIlDiYmJJCYmhnWNUBrg3wD6AJ1wH9q7gfleKeVI5x4FLMGVbNYD\ns4AbVTUp4JiKwFZVVRF5GkhT1X5e4/0coI2qbhGR94DZqvqmiFRR1Q1etdcgXMLrE+T+0WmAj/Y8\nXHmxfDnUr++mmB81KtbRGGMKAL8a4O/xHr4lIhOAMqoa0ldcVU0XkXuB73FVasNUNUlE+uMSw9dA\nAvCsiGQAPwE9vHMzRORhYIrXVDIHyFxOcJSIVMJVo80H7grp1fol2vNw5UW9eq7h/dJLYx2JMaYQ\ny21urrNzO1FV5/oSUQRFrWTSpo2bZPGmm/y/lzHG+Cyi06l4YzzAdQduBizAlQTOAH5T1fPCiDUq\nopJMkpPhwgvdlO7RnofLGGN8ENHpVFT1IlW9CNfWcbaqNlPVpsBZuB5XBlxvqdtus0RijCnSQmmA\nX6SqjY60LR75XjLZvdtN4T5vXmynTzHGmAjypQEeWCgi7+IWx1KgM2B9TCE+5uEyxpg4EErJpARw\nN3CBt+kn4E1V3e9zbGHztWQST/NwGWNMBNniWNn4mkx+/tmNKE9Kio/pU4wxJkIiWs0lIp+pakcR\n+Z3Dp0BBVeNn2vdYGDIE7r7bEokxxpB71+CqqrpeRIIuEp45zUk8861ksmEDNGzoJk+Mp+lTjDEm\nAiJaMvHmzCoQSSPq4nEeLmOMiaHcSia7CFK9hRu4qKpaxs/AIsGXkkk8z8NljDEREOmSic1VHkw8\nz8NljDExEso4EwBEpDKHrrS42peI4t2QIdCjR6yjMMaYuBLKSotXicgyYAXwI7AS+M7nuOJTcjL8\n/rtbwdAYY0yWUPq1PgWcCyxV1bq4tUlm+BpVvHrjDZuHyxhjggilmivVW5yqmIgUU9WpIvKy75HF\nm927YeRImD8/1pEYY0zcCSWZbBeRUrhpVEaJyD/AHn/DikOjRsEFF9g8XMYYE0Qoc3MdD+zHdQm+\nGSgLjFLVLf6HF56IdQ1WhSZN4KWXbB4uY0yhF+npVF4HPlLVXwI2j8hvcAXa9OmQkgKtW8c6EmOM\niUu5NcAvA14SkZUiMlBEiu7ACpuHyxhjchVKNVdtoJP3UwL4GPhEVZf6H154IlLNZfNwGWOKGN+n\noBeRs4D3gDNU9ag8xhd1EUkmTz/t1nd/553IBGWMMXHOl5UWRaQ40A5XMmmNG7jYP18RFjRpafD2\n224KFWOMMTnKrQG+LXAjcAUwC/gEuENVi0634PHjbR4uY4wJQW4lkz7AR8DDqro1SvHEF5uHyxhj\nQpLbrMEXRTOQuDN2rGsrsXm4jDHmiGwN+GA2b4bTT4cvvoCWLSMfmDHGxDHfe3MVNPlOJp06QfXq\nbsS7McYUMb705ipyvvgC5s2D4cNjHYkxxhQYVjIJtGkTnHEGjBkD553nX2DGGBPHrJormzwnk44d\noXZteOEF/4Iyxpg4Z9Vc4fjsM1i4EEYUzbksjTEmHFYyAfjnH1e99eWXcO65/gdmjDFxzKq5sgkp\nmajC9ddDvXowcGB0AjPGmDhm1Vz58emnsHixW5LXGGNMvhTtksnGja5666uvoHnz6AVmjDFxzKq5\nssk1mai6qVIaNIBnnoluYMYYE8fyk0x8XzpQRNqJSLKILBWR/wbZX0tEJonIAhGZIiLVAvbVFJGJ\nIrJYRP4QkVre9joiMkNElojIxyKS9+q6jz+GpUuhb9+wXp8xxhifSyYiUgxYilsHZR0wG+ikqskB\nx3wGjFfVkSKSANyiql28fVOBp1R1ioiUBDJUdb+IfAp8oaqfi8ibwHxVfTvI/YOXTNavd9PKf/MN\nNGsW6ZdtjDEFWjyWTJoDy1R1laqm4tZEuTrbMacBUwBUNTFzv4g0BI5S1cx9e1V1v3fOxcBo7/EI\n4NqQI1KFu+6C22+3RGKMMRHidzKpDvwd8HyNty3QfKADgIi0B0qJSHngVGCHiIwWkTkiMlCcisA2\nVc0IuGY1QjVqFPz1FzzxRP5ekTHGmMP43TU4WDEpe73TI8DrItIN+AlYC6ThYjsfOBOXkD4DugFf\nBblujnV1/fr1y3qc0LgxCQ89BN99B8cem4eXYYwxhVdiYiKJiYlhXcPvNpNzgX6q2s573htQVQ06\nOlBEjgeSVLWWiLQAnlXVi719nYEWqtpTRDYBJ6pqhnePvqp6WZDrHWwzUYWrroKzzoInn/Th1Rpj\nTOEQj20ms4GTRaS2iBwDdALGBx4gIhVFJDPoR4H3As4t71VrgWsnWew9ngJc7z3uCow7YiQffuhW\nTnz88fy+FmOMMTnwNZmoajpwL/A9sAj4RFWTRKS/iFzpHZYALBGRZKAyMMA7NwN4GJgiIgu8Y4d6\n//YGHhSRpUAFYFiugaxdCw8/DO+/D8ccE6mXZ4wxxlP4By1mZMCVV8I550BA+4kxxpjg4rGaK/ZG\njIB166BPn1hHYowxhVbhL5lUqgSTJkGTJrEOxxhjCgQrmQRz332WSIwxxmeFv2Ry4AAULx7rUIwx\npsCwkkkwlkiMMcZ3hT+ZGGOM8Z0lE2OMMWGzZGKMMSZslkyMMcaEzZKJMcaYsFkyMcYYEzZLJsYY\nY8JmycQYY0zYLJkYY4wJmyUTY4wxYbNkYowxJmyWTIwxxoTNkokxxpiwWTIxxhgTNksmxhhjwmbJ\nxBhjTNgsmRhjjAmbJRNjjDFhs2RijDEmbJZMjDHGhM2SiTHGmLBZMjHGGBM2SybGGGPCZsnEGGNM\n2CyZGGOMCZslE2OMMWGzZGKMMSZslkyMMcaEzZKJMcaYsFkyMcYYEzbfk4mItBORZBFZKiL/DbK/\nlohMEpEFIjJFRKoF7EsXkbkiMk9EvgzYPlxE/vK2zxWRM/x+HcYYY3LmazIRkWLA68ClQCPgRhFp\nkO2wF4H3VbUJ8CTwXMC+Pap6tqqeparXZDvvIW/72aq60K/XYA5KTEyMdQiFhr2XkWXvZ+z5XTJp\nDixT1VWqmgp8Alyd7ZjTgCkAqpqYbb/kcm2roosy+4ONHHsvI8vez9jz+wO5OvB3wPM13rZA84EO\nACLSHiglIuW9fceKyCwR+UVEsiehp0Vkvoi8JCLF/QjeGGNMaPxOJsFKFprt+SNAgojMAVoBa4E0\nb18tVW0O3Ay8LCJ1ve29VbUhcA5QETisLcYYY0z0iGr2z/YIXlzkXKCfqrbznvcGVFUH5nD88UCS\nqtYKsm848JWqjsm2/UJc+8lVQc7x78UZY0whpqq5NTMc5mi/AvHMBk4WkdrAeqATcGPgASJSEdiq\nLqs9CrznbS8H7FXVAyJSCfg/YKC3r4qqbhARAa4B/gh287y+GcYYY/LH12Siqukici/wPa5KbZiq\nJolIf2C2qn4NJADPikgG8BPQwzu9IfC2iKR75z6rqsnevlFeghFcm8tdfr4OY4wxufO1mssYY0zR\nUCi71x5poKTJGxFZ6Q0qnScis2IdT0EjIsNEZKOILAzYVl5EvheRJSIyUUTKxjLGgiSH97OviKzx\nBjHPFZF2sYyxoBCRGt5g8cUi8ruI3Odtz/PvZ6FLJiEOlDR5kwEkeINEm8c6mAJoOO73MVBvYJKq\n1seNs3o06lEVXMHeT4BB3iDms1V1QrSDKqDSgAdV9TTgPKCH93mZ59/PQpdMCG2gpMkboXD+rkSF\nqv4MbMu2+WpghPd4BK4jiQlBDu8n5D7I2QShqhtUdb73eDeQBNQgH7+fhfEDIpSBkiZvFJgoIrNF\n5PZYB1NIVFbVjeD+oIETYhxPYdDDG8j8rlUb5p2I1AHOBGYAJ+b197MwJpNQBkqavPk/VW0GXI77\ngz0/1gEZk80bQD1VPRPYAAyKcTwFioiUAr4A7vdKKHn+zCyMyWQNEDjosQawLkaxFAreNxNUdRMw\nFleVaMKzUUROBDduCvgnxvEUaKq6SQ92TR2Kmx3DhEBEjsYlkg9VdZy3Oc+/n4UxmWQNlBSRY3AD\nJcfHOKYCS0RKet9aMmcouIQcBomaXAmHlprHA928x12BcdlPMLk65P30PvAytcd+R/PiPWCxqr4S\nsC3Pv5+FcpyJ1y3wFQ4OlHzuCKeYHHjzoY3FFXuPBkbZ+5k3IvIRbnBuRWAj0Bf4EvgcqAmsBq5X\n1e2xirEgyeH9vAhX358BrATuzKzzNzkTkZa4weK/4/7GFegDzAI+Iw+/n4UymRhjjImuwljNZYwx\nJsosmRhjjAmbJRNjjDFhs2RijDEmbJZMjDHGhM2SiTHGmLBZMjGFgohkiMgLAc8fEpH/Rejaw0Wk\nfSSudYT7XOdNBT7Z73tlu29XEXktmvc0hY8lE1NYpADtRaRCrAMJ5C2JEKpbgdtUtbVf8eTCBpyZ\nsFgyMYVFGvAO8GD2HdlLFiKyy/v3QhFJFJEvReRPEXlWRG4SkZneYmB1Ay7T1ps1OVlErvDOLyYi\nz3vHz8+cUdm77k8iMg5YHCSeG0VkoffzrLftCeB8YJiIDAxyzsMiMsu7T19vW20RSRKRkV6J5jMR\nKeHta+0tErXAm0W3uLf9HBGZ7l1nhjdFDkB1EfnOWwxpYMDrG+7FuUBE7s/j/4kpQnxdA96YKFJg\nCPB7sA/jIMdmOgNoAGwH/gKGqmoLb8W5nhxMTrVV9RwRORmYKiL1cHMWbfeOPwaYLiLfe8efBTRS\n1dWBNxaRqsBz3v7twA8icpWqPiUiF+MWKpqX7Zy2wCmq2lxEBBjvzdz8N1Af6K6qM0RkGHCPiAzB\nLSB1kaouF5ERwN0i8iZufZ/rVXWuN+fafu82TXDTkaQCS0TkVeBEoLqqnuHFUeYI76spwqxkYgoN\nb+rsEUBevkHPVtV/VPUAsBzITAa/A3UCjvvMu8ef3nENcJNedhGRecBMoAJwinf8rOyJxHMOMFVV\nt6pqBjAKuCBgf7AlFC7BlYzmAnNxCSTzPqtVdYb3eCSudFMf+EtVl3vbR3j3qA+sU9W53mvZrarp\n3jGTvecpuNJUbVxyrSsir4jIpcCuILEZA1jJxBQ+r+A+cIcHbEvj0C9OxwQ8Tgl4nBHwPIND/z4C\nSzPiPRegp6r+EBiAiFwI7MkhvuyzB4dCgGdVdWi2+9QOcmxmXMHukdt9A9+HdOBoVd0uIk1wS+Te\nCXTEtesYcxgrmZjCQgBUdRuuFBH4obcSaAYgItcAxfNx/evFqQfUBZYAE3HVSkd71z5FREoe4Toz\ngQtEpIKIHAXcCCQe4ZyJwC2Z7RsiUk1EKnn7aolIC+/xjcA0IBmoLSInedv/7d0jGagqIk2965Ty\nYghKRCoCR6nqWOAJXNWcMUFZycQUFoElh5eAHgHbhgLjvOqoieRcasitR9Nq3LTcpXHTmx8QkXdx\nVWFzvbaMfzjCWtmqukFEHuVgAvlGVb/O7f6q+oOINAB+dbdhF9AZV3paglv9cjiwCHhLVVNEpDvw\nhZcsZgNvq2qqiNwAvC4ixwF7gTa5vA/VgeFejzQFeuf22kzRZlPQG1NAedVcX6vq6bGOxRir5jKm\nYLNvgyYuWMnEGGNM2KxkYowxJmyWTIwxxoTNkokxxpiwWTIxxhgTNksmxhhjwmbJxBhjTNj+HyTt\nnHdv/HIAAAABSURBVNnXNxeYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd4b179ca10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Varying learning rates')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.plot(lr1['epoch'],lr1['val_acc'],color='red',label='lr0.01')\n",
    "plt.plot(lr2['epoch'],lr2['val_acc'],color='green',label='lr0.001')\n",
    "plt.legend()\n",
    "plt.savefig('Varying learning rates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Varying Number of neurons in hidden layer')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.plot(res256['epoch'],res256['val_acc'],color='red',label='256')\n",
    "plt.plot(res600['epoch'],res600['val_acc'],color='green',label='600')\n",
    "plt.plot(res800['epoch'],res800['val_acc'],color='blue',label='800')\n",
    "plt.legend()\n",
    "plt.savefig('Varying Number of neurons in hidden layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEZCAYAAABSN8jfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd4VEXXwH8HpAmE3jui0lEQXooIKCiiNFEUKVJUEBBF\nBHmt1PcDERAEKQoIKIgUwQZSFJXeO6G30EsgCSX1fH/MTdyElE2ymwLze559du+ddu7d3Tl3Zs45\nI6qKxWKxWCzJIUNqC2CxWCyW9I9VJhaLxWJJNlaZWCwWiyXZWGVisVgslmRjlYnFYrFYko1VJhaL\nxWJJNlaZ3AWISKCIlE5tOZKLiDQQkVOp2H5rETkpIgEiUi215EgpRORREdmfxLKviMg/8aT/JiId\n40grJSIRIhJr/yQin4jI7KTIFR+p/ftK71hlksKIyDIRGRTL+ZYicjauP1ByUNWcqnrc0/WKyCDn\nT9/G5VxG51xJT7fnkJqOUaOAnqrqo6o7U1GOFEFV16hqheRUEU/dzVQ1PoWQ0Pfsrd+BdbxLIlaZ\npDzfALE9kXUAZqtqRGIqE5GMnhAqiShwGRgiIhLjfJomifetFLDP07IkllT+zi0e5E76Lq0ySXkW\nA3lF5NHIEyKSG3gWmOUcNxORbSJyTUROiMgnLnkjpwC6isgJYJWI/CIivV0bEZGdItLC+RwhImWd\nzzNEZIJTJkBE1otIGZdyT4qIr4j4i8hEEVktIl3juZ7fgRCiK8goxSIif7qWjzn94cj2hogcdK53\niIiUFZF1InJVRL4XkXuiX5r8V0QuishREXnZJSGziHzm3LOzIvKliGRx0hqIyCkRGSAiZ4HpMS9E\nDB+KyHEROSci34hITqfeQMz/ZZeIHIrtRjjX0t25lssiMiFGelcR2eekLY0cvcU2reN635x7tkZE\nxojIZeCTOGT1iVFfJ+deXBCR913qrikim537fVZEPovjeqJN+4jIMRHp5/y2/EVkrohkjq2syy0d\nJSJXROSIiDSN4/oyON/bRRE5DDwTo5LSzu/wmoj8DuSPkV5bRNY6Mm0XkQYx2hni3L8AMTMDeeOR\n2bXe90TksFNuj4i0cs5ndr7DSi55C4jIDRHJ5xw/68ji77RdJcZ9HCAiO4Eg8cJsRKqgqvaVwi9g\nKjDV5bg7sM3l+DGgkvO5MnAWaOEclwIiMCOcrEAW4AVgg0v5asBFIKNzHA6UdT7PAC4BNTCd47fA\nHCctH3ANaOmk9QGCga5xXMcnGAX4LHAEyOi8IoCSTp4/XcsDrwB/uxxHYBRsdqACcAtY4VxnTmAv\n0NHJ2wAIxUw3ZXLuUxBwv5P+uVNXLqe+JcDwGGX/55TNEsv1dAUOOm3fCywEZsWQtUw832sE8JMj\ndwngAvCkk9bKqfsB596+D6x1+U7DgQwudUXdN+eehQI9nbJZ4pPV5TcyBcgMVHXu64NO+jqgvfP5\nXqBWHNfTADjpcnwM2AAUAnJjRmmvx1H2FcxDRlfMw0UP4HQc19fDqauoU+8frvfDkTfyO68PBLhc\nazHM7/kp5/gJ5zifSzuHgPuc+/Yn8D83r7cNUMj5/ALmtxZ5PAH4P5e8fYAlzufqwHngEefaOzr3\nLpPLfdzmXO9tv8P0+kp1Ae7GF1APuBr5QwLWAG/Fk38sMNr5HNnxlHJJz+z8ge5zjkcBE1zSI4iu\nTFwV2dPAPudzR5wOziX9JAkoE+fzBoxSTIoyqe1yvAXo73L8GTDG+dwA00FldUmfB3zgfA7CpbMH\n6gBHXcreivxDx3E9K4EeLscPOO1lcJG1bDzlI4A6MWQb4Hz+DejikpYBuI5ROu4ok+PuyupSXxGX\n9I1AW+fzaue7y5fA7zQ2ZdLO5Xgk8GUcZV8BDrocZ3PuT8FYrm8VLkoJaBJ5P4CSznVlc0n/zuV3\nNwCYGaPtZfz7APIn8L5L2hvAb+5cbyzp24HmzudaMe7NZqCN8/lLYHCMsr5AfZf7+Ep89z49vu6M\n4VU6Q1XXYp5aW4qZYnoEmBOZLiK1ROQPZ3riKqaTzh+jGj+X+kKAH4AOIiJAOyC+xc1zLp9vADmc\nz0WBmNYsfrjHh8AHmNFSYrng8vkm5qnO9TiHy7G/qt5yOT4BFBWRApin7K3OtMoVYClmtBXJRVUN\njUeOok59rnXfg3kSdxdX2V3vbSlgnItslzFrS8XcrDfm9+KOrHHJ0g14EPAVkY0iEm1aKQHiqjM2\non5nqnrT+Rhb/pi/O9frKoL5zm/GkV4KaBt5X0XEH/OwVjg2OdyQOQpnmjByqsofqITzP1TVTZgp\nqgYi8iBm5POzi0z9YshU3LnOSNz9X6Ub7kk4i8VLzMY8vZUHlqvqRZe0OcB4zNA9VETGEr1ThNsX\nuWc5da4FrqvqxiTIdBZoEeNccXcKqupKZ767ZwzZrmM6+UgKkzzyiEg2l86lJLAbMzK7gZkePBuX\nmAnUfQbTEURSCjO9dD727IniFDBMVefGTBCRyAeFezGjK7j9PsWUPT5ZS8QniKoeAV522m4DLBCR\nvDE67JTkLNFlLhUjLbbvPNJQ5RRmlNLdkwI561lTgUaqut45tx2X9UBgJmY0fw5Y4DzURco0XFX/\nL54mEvotpjvsyCT1mAU0Bl7F/ChdyYF5GgsVkVo4f3wXJMYxqroB8wcbTfyjkvj4FagsIi3EmPj2\nJnFP5R9iph1c2QE8JyLZRKQc5qk4OQgwWEQyiUh9zGLtD2rmD74CPndGKYhIMRF5MhF1zwX6Ogu+\nOYDhwPeaSAu7OJgMvC8iFR3ZconI8wCqegk4jRlZZnAWpu9Lpqy3/UYiEZH2LgrsGqZjC0/qhXmA\nH4A+zveVB3gvMkFVT2KmPiO/80eB5i5lvwWaizEcySAiWZ3RQlGSR3bM/+mSU28XzPqlK98CrYH2\nOMYzDl8BPZz/LiKSXYxRTfZkypSmscoklVDVE5iFxXsxi7au9ASGisg1TAc9L2bxOKqdhfnBf+tm\n/pgyXcYsNI7CPOmXx/yRg90svw7YFKO9sZgn5nOY9ZqEZEtI1rOAP+bJfDbQXVUjraveAw4DG5zp\nweWYtQR3me7U+TfGoOAGZmHVXdnivBZVXQyMAL53ZNsFNHXJ+xpGEV/CGCKs9bCsrsdNgb0iEoD5\nfl50eaqOj+Q+TWscn7/CWAXuxPzeFsYo9zJQGzM1+BEuD1+q6ocxGHkfY3RyAniXf/u2JMmsqvsx\nD2YbML/dSpi1Tdc8pzEL6aqqa1zOb8V8nxOcKc2DmFmIqCxJkSmtI86CkPcaMOaAn2O+3GmqOjJG\neknMH6MA5sfSQVXPiEhDzA9dMU9Z5TE/+p9EZAZmsSzyqaqzqu7y6oWkA8R4FL+mqo95qD7BzO2+\nrKp/eaJOi+VOQkSmYazUPk5tWVIbryoTx376IMZc7wzG4uElVfV1yfMD8JOqfusokK6q2ilGPXkw\n5n3FVDXYUSY/qeqPXhM+nSEi92KsYiao6nfJqOdJjOXPLaA/xvqlrKq6NTqxWO4WxIQo2gY87Mw0\n3NV4e5qrFnBIVU84VjTfY4akrlTE2JWjqqtjSQd4Hlgao0OzU3QOjgK4gJkCum2BN5HUwUybXMCs\nR7S0isRiiY6IDMFMVX5qFYnB2x1yMaKb/PlxuynkDoxzECLyHJDDGYm48hK3d5LDRGSHiIwWkUwe\nlDndoarLVTWHqj6X3MViVR2sqvlVNZeq1lHVLZ6S02K5U1DVj9XEaBuR2rKkFbytTGKzKIk5r9Yf\naCgiWzHeraeBsKgKRApjFpV/dykzUE0AupoYk9n3sFgsFkuq4W0/Ez+MTXgkxTFrJ1E4PgGRI5Ps\nGC/SQJcsbYEfVTXcpcx55z3UWT/pF1vjInJHWk1YLBaLt1HVOM3LY8PbI5PNQDkxgecyY6aropnB\nikg+x2oI4L/cHoCvHTGmuJzRSqS1UStgT1wCpHaIgTvp9cknn6S6DHfKy95Lez/T8ispeFWZqBlN\n9MbY++/FOFXtF5HBIvKsk60hcEBEfIGCGOcrwEQ/BYrr7Wap3zkRN3diprmGefM6LBaLxRI/Xg+n\noqrLMHGAXM994vJ5Ibc7KUWmnSCW0BCq+oSHxbRYLBZLMrDmtRa3adiwYWqLcMdg76Vnsfcz9fG6\nB3xqIiJ6J1+fxWKxeAMRQRO5AG+jBlsslruO0qVLc+KE9TUsVaoUx48f90hddmRisVjuOpwn79QW\nI9WJ6z4kZWRi10wslruQ0PBQ6k2vx7w9MQNSWyxJwyoTi+UuZPKWyQSHBfPm0jdZf2p9aotjuQOw\n01wWy13GlZtXKD+hPH+88genrp2i609dWdt1LWXzlE1t0VIMO81lsNNcFoslyQz5awhtKrShcsHK\nPH3/03xY/0OenfMsV29dTW3RLOkYq0wslruIA5cO8N3u7xjSaEjUuV61etGkbBNemP8CoeGhqSid\nBSAkJIRXX32V0qVLkytXLmrUqMGyZcsAOHHiBBkyZMDHx4ecOXPi4+PD8OHDo5VfuXIlNWrUIEeO\nHJQqVYoFCxakiNzWNNhiuYt4d8W7DKg7gALZC0Q7P+apMbT8viW9fuvFlGen8G+4PEtKExYWRsmS\nJfnnn38oUaIEv/76K23btmXPHhOCUES4du1arN/Rvn37aN++PbNnz6Zx48Zcu3aNq1dTZsRp10ws\nlruEFUdW0OPXHuzruY8s92S5LT0wOJD6M+rTsWpH+tWNNRB32mTaNMifH1rGtq9e7KS3NZNq1aox\naNAgqlevTpkyZQgNDSVjxoy35Wvfvj3lypVj8ODBbtVr10wsFkuiCIsI453l7zCqyahYFQlAziw5\n+bndz4zdMJbFvotTWMIkcuQIDBgAr74KW7emtjRe4fz58xw8eJDKlSsDpqMvXbo0JUuWpGvXrly+\nfDkq74YNG1BVqlatSrFixejUqRP+/v4pIqdVJhbLXcC0bdPIly0frcu3jjdfiVwlWPLSEl7/+XW2\nnknjnbMq9OljlMnkydC6NZw/75m6RTzzSiZhYWF06NCBLl26cP/995M/f342b97MiRMn2Lp1K4GB\ngbRv3z4qv5+fH99++y0//vgjhw4d4saNG7z55pvJlsMtUjtuvpdj8qvFcrdz9eZVLTSqkG47s83t\nMj/u/1GLjS6mJ6+e9KJkyWTxYtXy5VWDg83xRx+p1quneutWgkXTQ98QERGhL774oj7zzDMaFhYW\na55z586piGhgYKCqqubKlUuHDh0alb5161bNmzdvnG3EdR+c84nqb+3IxGK5wxn+z3Ceuf8ZHi7y\nsNtlWpVvxdu136b53OYEBgcmXCCluXED3noLJk6EzJnNuUGDoEAB6N3bjFrSOd26dePSpUssWrQo\n1vWRSFzXPapWrRotTVPwPlhlYrHcwRy5coRp26cx7PHE7x/Xr04/ahWrRbuF7QiPCE+4QEoyfDjU\nqQOPP/7vuQwZYNYsWL/eKJl0TI8ePfD19eWnn34ic6SyBDZt2sTBgwdRVS5fvsxbb71Fo0aNyJkz\nJwBdunRhxowZHDt2jBs3bvDpp5/SvHnzFJHZWnNZLOmQVasgJASeesr0oXHR5oc21ChSg/frv5+k\ndkLDQ2k2pxmVClTi86afJ1FaD3PgANSrB7t2QdGit6cfPWoUzfffQ6NGsVaRlq25Tp48SenSpcma\nNWvUiEREmDLFmGy///77XLx4ER8fH5o0acKnn35KwYIFo8oPHjyYiRMnIiI8/fTTjBs3jly5csXa\nlietuawysVjSEYcPwzvvwP794OMDAQHQqxd06QIx+4vVx1fTeXFn9vfaT7ZM2ZLc5tVbV6k7rS69\navaiV61eybyCZKIKTz4JzZpB375x51u1Ctq3N6OUMmVuS07LyiQlsabBFstdRlAQfPAB1K4Njz4K\ne/bAli0wcyZs3AilS0PPnrBvn8kfHhHOO7+/w8jGI5OlSAByZ83Nry//yvB/hrPs8LLkX0xymD8f\nzp0z6yIO07dPZ+DKgWw6venfjvGJJ+D9943vSVBQKgl7d2GVicWShlGFuXOhQgU4edLM7AwYAFmy\nGMvTunVN+t69xm/v8cehSRPoO/4PsmbMTttKbT0iR5k8ZVjQdgGdfuzE7vO7PVJnogkMhH794Msv\nIVMmAGbtnMWQv4YgCJ1+7ETJz0vSZ2kfVh9fTVivN6BmTejUCSIiUkfmu4nEmn+lpxfpwPzPkn7w\nv+mvQ/8aqtWnVNfF+xd7vb3t21UffVT14YdV16xxr8ytW6pTp9/QTCW2atGSN3XUKNUrVzwn09zd\nc7XU2FJ6NvCs5yp1l3ffVe3UKepw2aFlWnBUQd13YV/UuX0X9umwv4Zp9SnVNf+n+bXbos76a/Py\nemvQh9Gqsn2DIa77QBJMg1O9w/fmy/5gLJ7gfNB5HbhioOYdmVdf+fEV/WHPD1p2XFnturirXrt1\nzePtXbqk+sYbqoUKqU6dqhqHi0GcfLDqA+2wqINu2KDavr1q7tyqr7+uunu3Z+Qb+tdQrTm1pl4P\nue6ZCt1hzx7V/PlVz51TVdUtp7dogU8L6JoTcWvZY/7HdMy6MVp/8n80939F2419VOfvna+BwYFW\nmThYZWKViSUFOHn1pPb5rY/mGZFH3/jlDT3mfywqLeBWgL665FUt83kZ/fv43x5pLzRUdeJE1QIF\nVN98M2kjiuP+xzXvyLx66tqpqHNnz6oOHqxapIhqw4aqCxeatpJKRESEdlzUUdvMa6PhEeFJr8j9\nBlUfe0x1wgRVVT1y5YgW+ayI/rj/xwSLXr+uevCg6sLxG7VL+W56f6uJmrnOJKtMHDypTKw1l8US\ng8NXDjNizQgW7V9E14e70q9OP4rkLBJr3p8O/ET3X7rTqWonhjQaEmfcq4T46y8TGSRvXhg/HqpU\nSZrs7Ra248F8DzKo4aDb0kJCYOFC+OILOH3aLNi3bw/Fiye+neCwYJrMbkLt4rUZ2Xikd6MMf/st\njBkDmzdz8dYV6k2vR9/afXmj5huAsXD74w9zTX5+5j3y882bUKyY8wo9TvH9y8nzdms+GFwQ2zd4\n1por1UcP3nxhnz4siWD3+d3abkE7zf9pfv34j4/10vVLbpU7H3ReW85tqVUnVdVd53Ylqs2TJ1Vf\nekm1ZEnV+fPNQ3hSWXtyrRYfU1yDgoMSzLtli2rXrqp586rWqqU6YoR5gk8Ml65f0mqTqmmnHzvp\njZAbSZQ6Afz9zZBq/XoNCg7SmlNr6gerPohK3rBBtWBB1c6dVT/+WHXKFNVff1XdsUP14sVY7mf/\n/qqNGtmRiUNc9wE7zWWViSXxbPLbpC3nttRCowrpiH9GJGkdJCIiQqdvm675P82vo9aO0rDw+Bc6\nbt5UHTZMNV8+0wleT+byQ3hEuNb6qpbO2jErUeVCQlRXrDBrNIULq1aubOTZscM9xRYUHKQvLXhJ\na0yp4Z04Xn36qL76qoaGh2qz75pp58WdNcIR7K+/zJTgL78kor6wMNWnn7bKxMEqE6tMLMkkIiJC\n/zz2pzaZ1URLjCmh4zeM98iC8tErR7X+9Pr62IzHoq2xuLJ6tWrZsqrPPad69Giym1RV1dk7Z2vN\nqTWTtYYRHq66dq1qv36qpUsbGd99V3XdOpN2G1euqPbrpxF+fjpq7Sgt/FlhXX1sddIvIibbt6sW\nLKgRFy5o18Vd9elvn9aQsBBVVf39d7Mev3JlEur197fKxMEqE6tMLEkkIiJCfz34q9adVlfLjS+n\nX2/9WoPDgj3aRlh4mI5cM1Lzf5pfZ2yfEfUkHRZmFsILFzZTMZ4iKDhIi48pHq9lU2KJiDB9+Ucf\nqVaqZGaaevY0nXdIiJoV/CefNLbLBQuqzpunyw8v14KjCuq4DeOirjnJhIer1qmjOnWqfvzHx/rI\n1Ec0MNhExv3pJzMi+eefpFefHvqGuXPnaoUKFTR79uxarlw5XePYh69cuVLLly+v2bNn18cff1xP\nnDgRVSY4OFi7dOmiPj4+WqRIER0zZky8bVhlYpWJxU1Cw0N125ltOnnzZO2yuIveP/5+rfxlZZ2z\na46GhifDpMkNdpzdoVW+rKKtv2+tu49c1CeeMNZUp097tp1Bfw7StvPberbSGPj6qv7f/6nWrGmm\n5jpX2qg/PfSR3gwMVd24UfWBB1Tbt9cjx7dr1UlVk7+OMm2aaq1aOnnTl3rfuPv0fNB5VVWdN8/o\nrk2bknc9ab1vWL58uZYuXVo3ORd65swZPXPmjF66dElz5cqlCxcu1ODgYO3fv7/Wrl07qtzAgQP1\nscce02vXrun+/fu1cOHC+vvvv8fZjlUmVplYYiEiIkKP+R/TeXvm6TvL3tFHpz+q2Ydn1woTKmjn\nxZ110uZJuvXM1pQxZ3W4FXpL246cohl8zuhLvQ4k2mckIU5dO6V5R+aNc0rNG5wYs0DH5RusDeqF\naL58xhcmIui6au/eqiVKaNDvP+uL819M+jrK5cuqBQvqkl9Ga+HPCuuhy4dUVfWbb8wIaefO5F9D\nWu8b6tatq9OnT7/t/NSpU7VevXpRx9evX9ds2bLpgQMHVFW1WLFiutJl7u+jjz7Sdu3axdmOVSZW\nmVjUeKQvP7xch/41VJvPaa4FRxXUwp8V1pZzW+r//v6frjyyUq/evJpq8oWFmcXsokVVx3y3U0t/\nXlpf++m1qOkaT9BxUUf978r/eqy+BNm40cwx7dmjqqZjr1lTtUED1QMHVHXZMtVixTTirT766Z/D\nk7aO0r27ruvznBb4tIBu8jNP5pMmqRYvrrp/v2cuIy33DeHh4Zo5c2YdMWKElitXTkuUKKFvvvmm\n3rx5U9966y3t2bNntPyVK1fWRYsWqb+/v4qIXrhwISptwYIFWrVq1Tjb8qQyuSdRdsQWSypy4foF\n5u+dz6Yzm9jot5HTgaepXqQ6/yn2HzpV68TEZhMp7lPcuz4PbnLmjPHhyJjRbE1euHBVugXv5O1l\nb1NtcjVGNRlF+fzlKZazGD5ZfJIk8+bTm1l5dCUHeh/wwhXEwpkz8Nxz8PXXUKkSAFWrmsC8X3xh\n4oT16/cU727dRaY+b9C/5woeGvMhbRe05YP6H/BmrTcTvs7NmzmweiGtu2VgZquZ1CxWk7Fjje/N\n6tVw333ev0wAGeyZ35B+knhflvPnzxMaGsrChQtZu3Yt99xzDy1atGDYsGEEBQVFCzcPkCtXLgID\nAwkKCkJEooWbj0xLCawysaQI16/DokVQsKBxkitWzIRMd7cPVVVeXvgyPll8eLrc0/Sr04+KBSpy\nT4a09xNevhw6d4Y33jCBayM3yfPJ4sP0ltNZ7LuYCZsm4Bfgh1+AHyJCsZzFKOZTjGI5i1Hcp/ht\nxwWzFyRjhn9321NV+v7el6GNhpIzS07vX9StW0aRvPEGtGgRLSljRnj7bWjVCnr0gO+/z8vXX31P\nzcNzadLpbdb36UjrbV+z9exWJj8zOe4oxuHhnO37Kk07wogmI3n6/qcZPhy++cY4dZYs6f3LjCQp\nSsBTZMtm7k+fPn2iFMc777zDsGHDaNCgAQEBAdHyBwQEkDNnTnLkyIGqEhAQQP78+aOlpQRp759o\nuSOZNg0mTzZ7GUV6KIeH/6tYihWL/jnyuFAh01ktO7wMvwuH2f3g52Sq3tJ9LZSChIWZnWO/+Qbm\nzIGGDWPP16p8K1qVbwUYpRAQHMDpwNOcDjiNX4AfpwNPs+fCHpYdWcbpgNOcDjyN/01/CuUoFKVc\nMmXMxPXQ63R+qLP3L0zVaImSJY12jIPSpWHpUnPtzVsI7du/zJB/HqNsr86su5WVbq9epv6M+vz4\n4o+UyFXitvIBU8bTrPYRXq0/kFeqdeb992HJEvj7bygSewCCO5LcuXNTPJawBCJCpUqV+Oabb6LO\nXb9+nSNHjlC5cmVy585NkSJF2LlzJ0888QQAO3fupJIzivQ6iZ0XS08v0vC86N3GQw/d7hNw7Zrq\nvn3Gae6bb1SHDzfOcy1aqNaoYQIdZsqkWqxYhGYrsU1r51miHxecpH9X7K7BK/5KnQuJAz8/1fr1\nVZs0UT1/3vP13wq9pcf8j+maE2t03p55OnrdaPW96Ov5hmJjzBjzBQYl7FkfyYULqh06GH+VZb+F\nq44bpxH58+mno5+LdR0l+KyfPtEtk/aY+YKGh0foW2+ZJl2m/z1KWu8bPv74Y61Vq5ZeuHBBr1y5\novXr19dPPvlEL168qLlz59ZFixbprVu3dMCAAVqnTp2ocgMHDtSGDRuqv7+/7t+/X4sUKaLLly+P\ns5247gN2Ad4qk7TItm2qpUrF4fiWACEhqiNHvK/VWj6q84b56nsDIrRGmUuaUwK0WYGNOvZdP929\nO3lhSJLL0qXGd2T48KRdY5pm+XJzccePJ6n4smVGoXTsqHpx7QHV6tV1+Us1teDI/FH+KOER4fpy\n/7La6v37NCQ0TF9/XfU///Fs6PyYpPW+ITQ0VHv27Km5c+fWIkWK6Ntvv63BwcYfatWqVVq+fHm9\n9957tVGjRrf5mXTt2lV9fHy0cOHC+vnnn8fbTrpSJkBTwBc4CLwXS3pJYCWwE/gDKOqcbwhsB7Y5\n7zeBFk5aaWADcACYC9wTR9vx3khLytC7t+qgQUkrGzR7mhbtn0E3rpwZ7fylM8H6Q9ff9PVss7RM\n9vNauECoduhgRjh+fh4Q2g1CQlTfe89YGf2VtgZKnuHQIePUkcyLCwxU7dvXjDS/mxmqER98qEfK\n5dOqI0pppx87ad/pL2rdHpk04Pw57dDBBAgOCPDQNcSB7RsM6UaZYHZyPAyUAjIBO4DyMfL8AHTQ\nfxXIrFjqyQNcArI4x/OAF5zPk4DucbSfnPts8QA3bxontyQ92H79tQ55Nqe+NO3puPMEBqoOGaJH\nclfXKQ2+0xea39C8eVUrVDBh3JcsMdNpnubkSdW6dVWbNvXeVEyqcu2auYmTJnmsyo0bVatUUX36\nadXjC7do0INl9aV3S2uFd7LomRlfaZs2xqk+uXHK3MH2DQZPKhOvhqAXkdrAJ6r6tHM80BFypEue\nPcCTqnrGOb6mqrli1PMa8JiqdnSOLwKFVDXCaWOQqjaNpX315vVZEmbePGNJumJFIgt+8QXnJo6k\n0ivX2dK6X6xqAAAgAElEQVRjG2XylIk//8WL8H//BzNnEt69JzueGsDKDTlZscLskV61KjRubLYG\nL1QoyZcDwO7dZgvyvn2hf3/IcKdtfh0RYUyzihWDSZM8WnVoKIwaZSLKfzQgmN5H+nLrzAVe1Plk\nzCj88IPZktjbxBV6/W7DkyHova1M2gBPqerrznEHoJaq9nHJ8y2wUVW/EJHngPlAflX1d8mzChit\nqr+JSD5gvao+4KQVB35T1aqxtG+ViYc4fvU4pXOXTnS5p54yZrLt2iWi0KefwpQp9BhWm+x5CzP6\nqdHulz1xwphU/forvPce9OrFTc3K2rWwcqXZ9+LatUReRAx8fODzz6FeveTVk2b58ENjQrVyJWTO\n7JUmDhyA1183FsfZs0OBAmbbEmdrd69jlYnBk8rE26bBsQkTU/L+wAQR6Qz8DZwGwqIqECkMVAZ+\nT0SdUQwaNCjqc8OGDWkYl72mJU7WnVpHven1mPPcHNpVcV8rnDwJW7bA4sVuFlCFwYNh3jz2L5nG\nwqUvcKBVIh3ySpWCGTNg71744AMYN45sgwbRuFMnGje2lvAJ8sMPplfftMlrigTgwQfhzz+NyfjB\ngzBixL/+OJaUZ/Xq1axevTpZdaTENFfUFFRs01wx8mcH9qtqSZdzfYCKqtrD5dwFoLDLNFfUVFqM\n+uzIJJmERYTxyNRHaHZ/M77a9hVru67lgXwPuFV26FA4dw4mTnQjsyoMGGA8/lasoMWqV2lQqgH9\n6vZL3gWsWwcDB8KlSzB8uJm+ic9HJSLCeFgGBJhXYGD094AAuOceePXVlHuMTil27IAmTcyc5EMP\npbY0XsWOTAzpaWSyGSgnIqWAs8BLQLRHW2fa6orT6/8XmB6jjnbAwBjn/gRewCzEvwIs8bzoFoAv\nN39J3mx5Gf74cErmKknb+W1Z32193F7MDhERZoAwf74bjUREwJtvmqfhP/9kdcAudl/YzfwX3Cmc\nAHXrGvfppUvhv/81j8AVKsStLK5fh3vvhZw5zXyWj8/tn/ftg59/NheXPXvyZUwKS5aYuaLGjU3H\nn9yFmwsXjKKdOPGOVyQW7+D1PeBFpCkwDmPZNU1VR4jIYGCzqv7irKv8HxCBmebqpaqhTtlSwBpV\nLRGjzjLA9xgrr+0Ya7DQWNq2I5NkcDbwLFUnV+Xvzn9ToUAFVJV2C9uRO2tuJj87Od6yf/5pQmzs\n2JGAs3p4OLz2mpnr+PVXInxyUuurWvSr0y9RU2puEREBP/0E/v5xK4ocORKebwkLMxP++/aZtZl8\n+TwrZ3yomiHf9OnQrJlZBLp8GR5/3CiWJk2MK3piCAkxZR97DIYN84rYaQ07MjGkmwX41MYqk+TR\nYVEHivsUZ0TjEVHnAoIDqDG1BkMaDom3s+/YER55BN56K54GQkOhUydjibVkCWTPzpzdc/h8w+ds\neHUDGSQNm0mpmtAiixfD77+nTOCo4GAzvXbggFGKhQub86dOmcXyyFfOnP8qlkaNIG/e+Ot94w0T\n32bx4jvQNC12rDIxeFKZeN1pMTVfWFvyJPPnsT+1xJgSsYZL33Zmm+b/NL8euHQg1rJXr6rmyqV6\n8WI8Ddy6pdqqleozzxhnFFW9GXpTS40tpX8dT0cegGPHGq/F3bu9287Fi2ZXwzZt4nfEiIgwceFH\njzYOHTlzqj7yiOp//6u6alXUvY5i0iTVihW944yThrF9gyGu+0Bac1pM7Zf9wSSNkLAQrTixoi7Y\nuyDOPJM2T9Jqk6rFupve5Mmqzz8fTwPXrxtvvzZtVIP/3TJ31NpR2mJui+SInjrMmWM8xZOzj2x8\n+PqqliunOnBg4uO13LplNp3/8EMToyRHDhNA7NNPVWfNMnIfOuQdudMwab1vOH78uDZr1kzz5Mmj\nRYoU0d69e2u4891v375da9Sooffee68+8sgjumPHjmhlBwwYoPny5dP8+fPrgAED4m3HKhOrTLzK\nqLWj9KnZT8W7j3dERIS+OP9F7f5z99vSatWKZ4/zgACzd22HDmYfcYdL1y9p/k/z6/6LHtr9KKX5\n/XezadSSJZ6t988/TYf/9deeqc/fX/XHH1V79TIjlhUrPFNvOiOt9w3NmjXTLl26aEhIiJ4/f16r\nVKmiX3zxhYaEhGipUqV03LhxGhISouPHj9dSpUppqPNfmjx5spYvXz5qm9+KFSvqlClT4mzHKhOr\nTLzGqWunNN/IfHrw0sEE8167dU3LjS+nc3bNiTq3e7fZWTA0tu3V/f1V69RRfe21256w3176tvb4\nuUdyxU9dNm0yQRE91fHPmGEUyapVnqnPEkVa7xsqVKigS5cujTru37+/9ujRQ5cvX67FixePlrdk\nyZJR+7zXrVtXv/rqq6i0adOmRYsqHBNPKhPrxWWJxju/v0PPmj25P9/90RPmzoXz56Od8gF+CG/J\nkz++Ro3lu3kgY0FmLKnPKxXDuWfCutsrnz0bHn3UuI+7mHgduXKEWbtmsa/nPi9cUQpSs6YxQ27a\n1JjaDhyYtH1XIiLgo4/g++9NfeXLe15WS5rm7bffZu7cuTRo0IArV66wdOlShg0bxt69e6laNXqw\nj6pVq7J3716efPJJ9u7dS7Vq1aLSqlWrxt69e1NEZqtM0jjbtxtDp6JFo28elS+f5/eHWn5kOVvO\nbGFmq5nRE9avN0Gonn/+tjIPA0Mz16Jt6Ff8dfVlvt3YjTUvjIPjl25v4NVXzSZLMQR//4/36Vu7\nL4VyJDNoVlrggQdgzRp4+mnjsTl2bOIspG7eNPFn/PxgwwYTZ8SS4njqv6VJNBh77LHHmDp1Kj4+\nPkRERPDKK6/QsmVLhg0bFm1bXoi+NW9QUNBt2/YGBQUlWf7EYJVJGiYgAFq3hubNjfXnokXGgtPP\nz8Q0Klo07h0KixUzu9O566QdHBZM7996M/7p8bc7JI4ZY7zT+/SJtWx3VVYvbEfb7RV48JGc3D/z\nQ7evcaPfRtaeXMuMljPcLpPmKVrUjChatoSXX4aZM92LXnj+vClTtiysWgVZs3pfVkusJFUJeKZt\n5amnnuKNN95g/fr1BAUF0aVLF9577z2KFCkS57a9ADly5IiWHhAQQI4cOVJO8Dv1RRqfF02I119X\n7do19rTr11UPHjTrs7Nnq44YYUKut25tFsCLFTO7FBYurFqzpuq6dfG3NeyvYdp8TvPbE44eNTHk\nA283EXbl2q1rem+lVdp96Hr3Lk7NIv6j0x/VadumuV0mXXHzpupzz6k2bpzwBh179phdpD7+OHV3\n+rpLSMt9w6VLlzRDhgwa4PKbWbx4sVapUkVXrFhx25pJqVKlonZTrFu3rn7tsmaXkmsmqd7he/OV\nln8wCbF8uWqJEqpXB401ZpxJIDTUbBQ1Y4bpp+JyJTjmf0zzjsyrR68cvT3x7bdVEzAvVFU9fVo1\nZ65QzTe0VJz+JzFZtG+RVvmyioaFh7mVP10SFmaeCmrUiHs/3+XLjSXY7NkpK9tdTFrvG+677z4d\nOXKkhoWFqb+/v7Zu3Vo7duyoISEhWrp0aR0/frwGBwfrF198oaVLl45mzVWxYkU9ffq0nj59WitV\nqqRTp06Nsx2rTO5wZXLtmmrJkqrL+q80H/LmTcADMGFeey3uUU6LuS106F9Db0/w91fNk0f11KkE\n6x8xQrVbt/j9T1wJCQvR+8ffr0sPLY033x1BRITqJ58YX5EjR6KnTZlitiD8++9UEe1uJa33DTt3\n7tSGDRtqnjx5tECBAtq2bVu96PQBO3bsiPIzqVGjhu7cuTNa2ffee0/z5s2r+fLl04EDB8bbjlUm\nd7gyefVV1deanzFPq3v2qHbvbjyYk0FgoGrZssbFwJWfD/ys94+/X2+F3rq90KhRqu3bJ1h3RITq\nAw+orl0bv/+JKxM2TtDGsxrH68tyx/Hll8Zuevt2M2Lp18/cuLvQaTC1Sa99g6exyuQOVibLlqmW\nLBqi1wrcZw5UzZ63efOqXr6crLrXrDEPwefOmeMbITe0zOdl9PfDv9+eOSTEzLNt2eJWvQ8++O9U\nf2z+J65cu3VNC40qpNvPbk/qpaRf5s83DwmNGxvnzWR+p5akkR77Bm/gSWVyd0R1SydcuwavdYtg\nWobX8Rncz2xTCGbDp+eeM/4ZyaBePejWzVjoqsKINSOoUbQGT9735O2ZFy40VkU1aiRY7/Tp0LXr\nv+aUPll8+OH5H+izrA8HLx+8Lf/INSNpWq4pDxW+C0OdP/+82YCqenUTIDKhIIwWSzrBRg1OQ3Tr\nEk6m5b8y+cXVxhzXlaNHoVYtOHQI8uRJchshIVC7NrTpdIGxIRXZ0WMHxX2KR8+katr66CNo0SLe\n+oKCoEQJE429SJHoaZO3TGbylsnR9j/xC/Cj2uRq7Oyx8/Z2LZYUwkYNNngyanCCIxMRqZyYCi1J\nY+lvyqoF/ox6aA6MGnV7hrJljcPJ+PHJaidzZpg9Wxn8cRa6lf5f7B36mjVmmPTsswnWN38+1K9/\nuyIB6F6jO+Xzl6fv732jzn34x4d0r9HdKhKL5Q4jwZGJiKwBMgPfAHNU9WoKyOUR0svI5OpVqFI6\ngG8KDOCJ7Z+ZDZpi4/BhqFPHvMfwgk0Mi/YvoudHByhz+j3++ScD98R0XW3dGp580uxzkQD160O/\nfmaTvthw3f+kYoGKPPXtUxzofYBcWZMuv8WSXOzIxJDim2OJyP1AV8xWuZuAGaq6IjENpQbpRZl0\naXScbJv/5ssDTxjX9fjo1MmE7PjQfS9zV66HXKfCxAp803IWw19ryBNPmD2eojh0yCyuHD9utq+N\nh4MHjTLx84vf03772e08+e2TlMldhk7VOtG7Vu8kyW6xeAqrTAypsjkWkBFoA5wG9gO+wHOJXfFP\nyRfpwGLjl9G+WibDMQ1csyPhzKpmb4v8+RP2qI6DgSsG6ssLX1ZV1ZMnjWHR1q0uGXr1Uv3gA7fq\n+u9/jXWrO0zePFkrf1lZQ8JCEimxxeJ5SpUqpcBd/ypVqlSs94ckWHO5M81VFegCPAOswOzjvk1E\nigLrVbVUvBWkIml9ZOK/6xRVHs7It0OO0fCDeu4XbN8eqlQxUWkTge8lX+rPqM+uHrsoktMscsyZ\nA8OHw5YtkO3mFShXDvbujX0RxIWwMGNktnw5VKrkXvsRGpG2t+K1WCyAl6a5RORv4CtggarejJHW\nUVVnJ1rSFCJNK5OAADqVWk2uyiX44p+HE1d23z6zt/eRI3Gvr8RAVWk8uzEtHmjBW7XfcjkPL71k\nYhOOLTQCfH3hm28SrO+332DIEBPY1mKx3FkkRZm4EzW4GXBTVcOdRjIAWVX1RlpWJGmasDB+bjSG\ntRG92LU0f+LLV6wIDRvCpEkmNLwbzNs7j8s3LtOrVq9o50VMNVWrKs/e2s4Tq96Po4boRPqWWCwW\nC7g3MtkANFbVIOc4B7BcVeumgHzJIk2OTFS58uoAqnz3HnOX5uaxRkncBWDPHmjc2PifJLBQHhAc\nQIWJFfjh+R+oVzL26bTf+6/ktS+qsutcQXLnjr/pixfh/vvhxIlkGZVZLJY0iremuXao6kMJnUuL\npEllMm4cHT65j3wvNWHcZDf2uIgDVeVm29YE1H6YgM7tCAwOJCA4gMAQ8x4QHBB1btOZTRT3KR73\nniGqUL06b5b4EX+f0nz7bfxtf/45bNsGs2YlWXyLxZKG8dY013URqa6q25xGagA3EyhjiY2ff2bx\n4J1szNOTHaMT3rXq6q2rTNg0gTUn1/yrIBxlERgcSKaq95Dz4s/4fDsLn6y5yJklJz5ZfPDJ4kPO\nzDmj3ls80IKO1TrG3dCff0JwMCPnlKT6IzBvHrz4YuxZVc0UVzJ9Jy0Wyx2GO8rkbWC+iJxxjosA\ncXQ1ljjZsYPLnfvRM+MefpidiezZ48564foFxq4fy9RtU2n+QHPerPUmubLmiqYocmbJSeaMmY23\nYNHHoXvsuyC6xZgx0Lcv9+bIwOzZxvH90Udjd3nZuhWuX4fHHkt6cxaL5c7DXafFTMCDgAC+qhrq\nbcE8QZqZ5jpzBmrX5uWSayhUsyRjx8ae7dS1U3y27jNm75rNS5VfYkC9AZTOXTr+urdtM/GzDh9O\n2javvr7QoIFxUsxm4mcNGWIiqixbdvv25T17Gqvhjz5KfFMWiyV94E0P+MpARSCqt1LVND9jniaU\nifMYv6j8+wzc3IYdO25fLz985TAj1oxg0f5FdH24K/3q9IvyA3GL5s2haVPo1SvhvDHp3t1oh0GD\nok6FhRkn+I4dobeLs/rNm2a0smMHlCyZ+KYsFkv6wFsL8J8ADTHK5DfgaWCNqj6fRDlTjFRXJuHh\n0KYNl7KVoMrq8SxYINRzMabac2EP//vnfyw/spyeNXvy1n/eIt+9+RLfzubNJkT94cOQJRGL+hcv\nmtAsBw5AwYLRkg4ehLp1zQilfHlzbs4cmDnTRE63WCx3Ll6JGgw8DzwBnFPVLkA1wBqEusOiReDn\nR+/wz2nf/l9Fsvn0Zlp934rGsxpTrVA1jr51lCGNhiRNkQDUrGk84t1wNozG5Mlmf40YigSMjhk6\n1IxOQp1JTetbYrFY4sKdkckmVa0lIluBRkAgsF9Vy6eEgMkh1UcmDRuyoPr/+PC3umzbpmy+8DfD\n/xmO7yVf+tftT7fq3bg3U/w+Im6zfj20a2eGFJkzJ5z/1i0oUwZWrowzHooqNGtmtjbp0gUeecQE\ndUzK0ozFYkk/eMs0eIuI5MaEVNkKBAHrkyDf3cWePVz2vcibB+rQf/w6nvx+AOevn2dgvYF0rNbR\nWGJ5kjp1zHBi1iyzlWJCzJkDDz0Ub2AtETMaeeghs07Srp1VJBaLJXbiHZmIiADFVfWUc1wa8FHV\nXSkiXTJJ1ZFJr1703tmaeRmuUbjdIN5/9H1eqPQC92RIose7O6xda+alDhyIPya8qpkWGzsWmjRJ\nsNqFC81s2LZt8HAiw4hZLJb0h7cW4HerapVkSZZKpJoyCQjgcsmHKRq2nc6TJzCp/cCUi5b7xBPQ\noYOZl4qL5cvh3Xdh585/N25PgO3brSKxWO4WvKVMZgITVHVzcoRLDVJNmUycSMcpOVmcPRPn/27p\nuXURd/jrL+jWzfiP3LaFosNTT5k5q86dU04ui8WSbvCWNdd/gPUickREdonIbhFJF9NcqYIqF7+Y\nxdwjzRkxOFfKKhIwDojFisHcubGn79kDu3cbZWKxWCwewp2RSaybX6nqCbcaEGkKfI5RXNNUdWSM\n9JLAdKAAcBnooKpnnLQSwNdACSACaKaqJ0VkBtAAuIbZMaxzbOs4qTIyWb2aZt23sL1QJc781RRx\ncxrJo/zxh9m/fd8+yJgxelq3blC2LHzwQcrLZbFY0gXesuZKcm/s7H0yAeOncgbYLCJLVNXXJdtn\nwDeq+q2INARGAJ2ctFnAUFX9Q0TuxSiUSPqp6o9Jlc1bHB0/mWV+E/l55qXUUSRgNs4qUMBEbHz5\n5X/PnztnfF8OHUoduSwWyx2LO9NcvwK/OO+rgKPAUjfrrwUcUtUTTjyv74GWMfJUBP4AUNXVkeki\nUgHIqKqRaTdU9VYiZU9ZTp/mJd/yPPifgzxT+8HUk0MEPv4Yhg0zXviRfPml2VYxfxI25LJYLJZ4\nSLBDVtUqqlrVeb8foyDc9TMpBpxyOfZzzrmyA2gDICLPATlEJA/wAHBNRBaKyFYRGSnRH/WHicgO\nERntBKJMdf6Z8ClbTvRi5tiKqS2KMfnNlQsWLDDHN28aj/e3305duSwWyx1Jop/unX1N/uNm9tjm\neWJOm/UHGjoe9vWB00AYZgruUeAdoCZwH9DZKTNQVSs45/MB7yXiEryChoTQ8Y+c1HzkLLWqpYFo\nM5Gjk6FDISICZs+G2rXhwVQcMVksljuWBNdMROQdl8MMQHXM+oc7+AGu8WWLxyyrqmf5d2SSHWij\nqoEi4gdsj1zoF5HFGCU2Q1XPO2VDncX4fnEJMMglGm7Dhg1p2LChm6Injm+mfMDp3QP4ZXNer9Sf\nJJo2NQpl4UKzZ8nkyaktkcViSYOsXr2a1atXJ6sOd6MGRxIGHAcWxli/iKtsRuAAZgH+LLAJaKeq\n+13y5AOuqKqKyDAgTFUHOYv3WzH7z18WkenAZlWdJCKFVfWcM+01Bripqu/H0n6KWHMFhQRR/Kn/\n8ciNl1m5sbLX20sUv/xivOLLlDE7W6WWUYDFYkk3eMWaS1UHJ1UgVQ0Xkd7Acv41Dd4vIoMxiuEX\nTHj7/xORCOBvoJdTNkJE3gX+cJZKtmLigwF8JyL5MdNoO4AeSZXREwyeM5DgDR/y+bokRv31Js88\nAxUrwltvWUVisVi8hjsjkxXAC6p61TnOA3yvqk+lgHzJIiVGJkeuHKHqS1/RyO8lftn3kFfbSjIR\nEbdvmWixWCxx4C0/kwKRigRAVf1F5PYNMO5S+izqT8a/vmT4L2n4qd8qEovF4mXc6WXCHS91IMoj\nPg1srJ76LDu8jI2LKtAo/wmqNSmU2uJYLBZLquHOyOQDYI2I/OUcPwa87j2R0gch4SH0+XkAumo5\ng744lXABi8ViuYNJcM0EwFnsro1Z8F6vqpe8LZgn8Oaayeh1o5k+VrlvWXV+CmhkF7ctFssdg1ei\nBotIayBUVX9R1Z+BMBFplVQh7wTOBZ3jf6tHc+W3V/j4jUtWkVgslrsed6y5dqjqQzHObVfVNL9V\nkrdGJl2WdMHv1yfJPCMfv16uDT4+Hm/DYrFYUgtv7WcSWx4v7j2bttnot5Flvn/gO+9pPmq+wyoS\ni8ViwT1lskVExojIfSJSVkTGYhwI7zoiNII3l77J04HfUfHWDmoPaZbaIlksFkuawB1l8iYQAswD\n5gO3cLzU7zZm7piJRGTmz6kP8UmFH6ByGgudYrFYLKmEW9Zc6RVPrplcu3WN8hPL8yrrWD/sCiun\nHIG2bT1St8VisaQlkrJm4s4CfAFgAFAJyBp5XlUfT4qQKYknlUm/3/vhfyOQv/pMYMaNF3ns3A+Q\nKU1so2KxWCwexVsL8N8BvkAZYDAmavDmREuXjtl/cT+zds3i4YufUSLiOI/1rmoVicVisbjgzshk\nq6rWEJFdqlrVObdZVWumiITJwBMjE1Wl6XdNebJ0M6Z07s2Uc61odGAyFIu5YaTFYrHcGXgr0GOo\n835WRJ7BbG6VhnaA8i4/HfgJvwA/8h/rRSHO07BpVqtILBaLJQbuKJNhIpILs5vhF4AP0NerUqUR\nboXdou/vfZnUbCpvNc/IFyEfIb16prZYFovFkuZwZ3OsX5yP14BG3hUnbTF63WgeLvIw/lsbkzfj\nNRrn2AANv05tsSwWiyXNcdd6sidEhEYwat0otry2jZaPwei8E5CXeto4XBaLxRILVpnEgV+AH/dm\nupcdf5Yle6YQntr9Gfx6IrXFslgsljSJVSZx4HvJl/L5KjJkCPxfpR+Quu1sHC6LxWKJgwSViYhk\nAdoApV3zq+oQ74mV+vhe8iXLobZkukdptnoArFie2iJZLBZLmsUdp8UlQEsgDLju8rqj2XdhP7sX\ntObjJ9YiD9xv43BZLBZLPLgzzVVcVZt6XZI0xrrVOclENlps/AB635VxLS0Wi8Vt3BmZrBORKl6X\nJI3hu7gV77Q/jhw+BK1bp7Y4FovFkqZxZ2TyKNBZRI4BwZh94DUytMqdyPLVgYT5F6XHmVHw2ms2\nDpfFYrEkgDuxuUrFdl5V07ydbFJjczV46grHc03mxKrRsGuXDZ9isVjuKrwSNdhRGrmB5s4rd3pQ\nJEll3z7YsSUbdXN9Be+9ZxWJxWKxuEGCykRE3sKEoS/ovL4VkTe9LVhq8emnUK3m91S+EQb9+qW2\nOBaLxZIucGeaaxdQR1WvO8fZgfXpYc0ksdNcJ0/CQ1XD+U/TIrz26oc817iPF6WzWCyWtIm3NscS\nINzlONw5d8cxZrTSLed8jlaE8tUap7Y4FovFkm5wx5prBrBRRH50jlsB07wnUupw6RLM+jqYbRW/\n5YsMAdyX577UFslisVjSDe6EoB8jIqsxJsICdFHV7d4WLKWZMOQKbcJ/5cbENyi58SBZ7smS2iJZ\nLBZLuiFOZSIiPqoaICJ5Mfu+H3dJy6uqV7wvXsoQFBDBxEkZWPtuKHtyBlOhQIXUFslisVjSFfGN\nTOYAzwJbAddVbHGOy3pRrhTl61f+oWGuCB4Y9grz146gfL7yqS2SxWKxpCviVCaq+qzzXiblxEl5\nQvYeYvRP5fhxfjhkzIjvZV8eL/14aotlsVgs6Qp3/ExWuXMuXRIezpxWP1C+XDiPPFcSMKHn7TSX\nxWKxJI741kyyAvcC+UUkD/+aA/sARVNANq8T8fl4Rp7uwIQlxQFQVXwv+fJgvgdTWTKLxWJJX8Q3\nMumOWS8p77xHvpYAE91tQESaioiviBwUkfdiSS8pIitFZKeI/CEiRV3SSojI7yKyT0T2iEhJ53xp\nEdkgIgdEZK6IJH7HyIMH+WnwNnKUK8Tjjc1tOB14muyZspMnW55EV2exWCx3M3EqE1Ud56yXvKuq\nZVW1jPOqpqoT3KlcRDIAE4CngEpAOxGJubr9GfCNqlYDhgAjXNJmASNVtSJQC7jgnB8JjFbVB4Gr\nQDd35IkiPBx9pTP/l3cUAz/JijhjLjvFZbFYLEnDHT+TL0SkMlARyOpyfpYb9dcCDkUGhhSR7zG7\nNvq65KkIvO3UuVpEljh5KwAZVfUPJ+2GS5nHgXbO55nAIGCKG/IYPv+cv27W4mqWQrRq9e/p/Rf3\nW0sui8ViSQLuLMB/AnzhvBoBnwIt3Ky/GHDK5djPOefKDswe84jIc0AOZ43mAeCaiCwUka0iMlIM\n+QB/VY1wqdP9NRxfXxgxghE+/2PAACFjRpekS76Uz2+VicVisSQWd2JzPQ88AZxT1S5ANSCXm/XH\nFsMrZuTF/kBDEdkK1AdOY/abvwfjdf8OUBO4D+js1BmzXveiOYaHQ5cubO82gd1H7qVDh+jJvpft\nNLVvfqwAABE4SURBVJfFYrEkBXcWrm+qaoSIhImID2bdooSb9fsBJV2OiwNnXDOo6ln+HZlkB9qo\naqCI+AHbXabIFgP/UdUZIpJbRDI4o5Pb6nRl0KBBUZ8bnjtHw6xZGXmsLe+8A1liREzZf3G/HZlY\nLJa7jtWrV7N69epk1eFOCPovgfeBl4B+QBCwwxmlJFQ2I3AAM7I5C2wC2qnqfpc8+YArqqoiMgwI\nU9VBzuL9VqCxql4WkenAZlWdJCLzgEWqOk9EJgE7VXVyLO3/G4J+/36oX5/D87dT+4USHDsGOXP+\nm/farWsUG1OMgP8GkEHcGbBZLBbLnYm3dlrsqapXnc66CfCKO4rEKRsO9AaWA3uB71V1v4gMFpFn\nnWwNgQMi4ovZfGu4UzYCeBf4Q0R2Onm/ct4HAu+IyEEgLwlFMQ4Lg86dYehQPptXgjfeiK5IAA5c\nPsCD+R+0isRisViSQJwjExGpHl9BVd3mFYk8SNTIZORIWLGCszOXU6lKBg4cgAIFoueduWMmy48u\n57vnvksdYS0WiyWNkJSRSXxrJqOd96zAI8BOzMJ3VWALUCcpQqY4e/fCZ5/Bli2M+yID7dvfrkjA\nseSyZsEWi8WSJOJzWmykqo0wax3VVfURVa0BPIyxuEofdO4Mw4dzLXcpvvoq7m3drSWXxWKxJB13\nFggeVNXdkQequgdIP71unjzw2mtMmgTNmkHp0rFns5ZcFovFknTcMQ3eJSJfA99i/Dk6ALu8KpUn\n+fprbt4Sxo2D5ctjzxIaHsrxq8e5P+/9KSubxWKx3CG4o0y6AG8AbznHfwOTvCaRpylZkpmT4ZFH\noEqV2LMc8T9CiVwl7Fa9FovFkkTcic11CxjrvNIdYWEwahTMiieSmJ3islgsluQR334mP6hqWxHZ\nTSzhSlS1qlcl8xALFkDRolCvXtx5rCWXxWKxJI/4RiaR01rPxpMnzTNiBAwfHn8e38u+NCjVIGUE\nslgsljuQ+PaAP+u8n0g5cTxPeLix4oqP/Rf3071G95QRyGKxWO5A4pvmCiT2aLwCqKr6eE0qDzJw\nIFGbX8VG5Fa9ds3EYrFYkk58I5OccaWlJ158Mf70s0FnyZYpG3mz5U0ZgSwWi+UOxO2900WkINF3\nWjzpFYk8zD0JXKG15LJYLJbk485Oiy1E5BBwDPgLOA4s9bJcKYa15LJYLJbk4044laFAbeCgqpbB\n7E2ywatSpSC+l2xMLovFYkku7iiTUFW9DGRwdjf8ExNF+I5g/yU7zWWxWCzJxZ01k6sikgMTRuU7\nEbkAXPeuWCmHteSyWCyW5OPOyKQlcBPoCywDjgDNvSlUShEYHIj/LX9K5iqZcGaLxWKxxEl8fiYT\ngDmqus7l9Ezvi5Ry+F7y5YF8D9itei0WiyWZxNeLHgJGi8hxERkpIg+llFAphZ3islgsFs8Q306L\n41S1DtAAuALMEJH9IvKxiDyQYhJ6Ed9LvlTIby25LBaLJbkkOL+jqidUdaSqPgy8DLQG9ntdshTA\nWnJZLBaLZ3DHaTGTiDQXke8wzooHgTZelywFsNNcFovF4hniW4BvArQDngE2Ad8Dr6vqHWEWHBoe\nylH/ozyQ746YsbNYLJZUJT4/k/eBOcC7qnolheRJMY76H6WYTzGy3pM14cwWi8ViiZf4ogY3SklB\nUho7xWWxWCye4651sLCWXBaLxeI57lplYi25LBaLxXPctcrETnNZLBaL57grlUnkVr12mstisVg8\nw12pTM4FnSNTxkzkuzdfaotisVgsdwR3pTKxU1wWi8XiWe5aZWKnuCwWi8Vz3JXKxFpyWSwWi2e5\nK5WJneayWCwWz3LXKhM7zWWxWCye465TJkEhQf/f3r0HW1WWcRz//hCxAEuBBMW4pCjq5C1vqaOo\nqXQZNcqSprxkjZWaM5qJzZhYFmDqjIWVIR6dtMzMe1N4wTOWhtAc8MrFG3kL8MaM4qRwztMf6z26\n3O5zOJt9Ftuz9u8zw5y93nV79mLt/ez3Xet9Fy+/+bIf1Wtm1osKTyaSJkpaImmZpHOqzB8l6W5J\nD0maK2mb3Lx2SW2SFkq6JVfeIunpVN4madeexrP05aWMGzqOTfptUv+bMzMzoPtRg+smqR8wEzgM\neBFYIOnWiFiSW+xi4OqIuFbSBGA6cHyatyYi9uxi82dFxM21xuQmLjOz3ld0zWQf4In0tMa1ZM9E\nObpimZ2BuQAR0VoxX91se4Ni951cZma9r+hkMhJ4Ljf9fCrLW0R6cqOkScBgSVumeZtJmi/pAUmV\nSehCSYskXSJp054G5Du5zMx6X6HNXFSvWUTF9NnATEknAvcBLwDr0rxREbFC0lhgrqSHI+IZYEpE\nrExJZBZwDnBhtQCmTp36zusJEya4mcvMrEJrayutra11bUMRld/tvUfSfsDUiJiYpqcAEREzulh+\nELA4It53q5WkFuD2iLipovxgsusnR1VZJ/Lvb13HOjaftjmv/PAVBm46sJ63ZmZWWpKIiO4uM7xP\n0c1cC4DtJY2WNAA4Drgtv4CkoZI6gz4XuCqVb5HWQdIwYH/g8TQ9Iv0VcAzwaE+Ceea1ZxgxeIQT\niZlZLyu0mSsi2iWdBtxJlrhmR8RiSRcACyLiDmACME1SB1kz16lp9Z2AKyS1p3Wn5e4Cuy4lGJFd\nc/lOT+JxE5eZWTEKbeZqtMpmrovuv4gVb6zg0iMvbWBUZmYfbB/EZq4PFN/JZWZWjKZLJm7mMjPr\nfU2TTCLCHRbNzArSNMlk1ZpV9FM/hg0c1uhQzMxKp2mSSWcT17t3IZuZWW9pmmTiJi4zs+I0TTLx\nnVxmZsVpqmTiO7nMzIrRNMnEzVxmZsVpimSy5u01rFqzijFbjGl0KGZmpdQUyWTZK8sYN8SP6jUz\nK0pTJBM3cZmZFaspkonv5DIzK1bTJBPfyWVmVpymSCZu5jIzK1bpk0l7RztPvvokOwzdodGhmJmV\nVumTyfLVyxk+aDiDBgxqdChmZqVV+mTiJi4zs+KVPpn4Ti4zs+I1RTLxnVxmZsUqfTJxM5eZWfHK\nn0xecjIxMyta6ZMJwFaDtmp0CGZmpVb6ZDJ+2Hg/qtfMrGBNkUzMzKxYpU8mvpPLzKx4pU8mrpmY\nmRXPycTMzOqmiGh0DIWRFGvb19K/X/9Gh2Jm1mdIIiJqunOp9DUTJxIzs+KVPpmYmVnxnEzMzKxu\nTiZmZlY3JxMzM6ubk4mZmdWt8GQiaaKkJZKWSTqnyvxRku6W9JCkuZK2yc1rl9QmaaGkW3LlYyTN\nk7RU0h8l+ZYtM7MGKjSZSOoHzASOBHYBJkuq7EV4MXB1ROwG/ASYnpu3JiL2jIg9IuKYXPkM4JKI\n2BFYDZxc2Juwd7S2tjY6hNLwsexdPp6NV3TNZB/giYj4T0SsBa4Hjq5YZmdgLkBEtFbM76rTzKHA\nX9Lra4Av9lbA1jV/YHuPj2Xv8vFsvKKTyUjgudz086ksbxHwJQBJk4DBkrZM8zaTNF/SA5KOTssM\nBV6LiI7cNrfBzMwapuhrDdVqFpXjt5wNzJR0InAf8AKwLs0bFRErJI0F5kp6GHi9ynbLOyaMmVkf\nUOjYXJL2A6ZGxMQ0PQWIiJjRxfKDgMURMarKvBbg9oi4SdIqYEREdKR9nB8Rn62yjpOMmdkGqHVs\nrqJrJguA7SWNBv4LHAdMzi+Qmq1ejSyrnQtclcq3AN6MiLclDQMOILvwDnAvcCzwJ+AE4NZqO6/1\nYJiZ2YYp9JpJRLQDpwF3Ao8B10fEYkkXSPpCWmwCsFTSEmAr4GepfCfg35IWAvcAP4+IJWneFOBM\nScuAIcDsIt+HmZl1r9RD0JuZ2cZRyh7w6+soabWRtDx1Kl0oaX6j4+lrJM2WtDLdQNJZtqWkO1PH\n2zmSPtrIGPuSLo7n+ZKeT52c2yRNbGSMfYWkbVNn8cclPSLp+6m85vOzdMmkhx0lrTYdwITUeXSf\nRgfTB7WQnY95U4C7U8fbuWTXC61nqh1PgEtTJ+c9I+LvGzuoPmodcGZE7Ax8Gjg1fV/WfH6WLpnQ\ns46SVhtRznNlo4iIfwKvVRQfTdbhlvT3GKxHujie0HUnZ+tCRKyIiEXp9RvAYmBbNuD8LOMXRE86\nSlptApgjaYGkbzc6mJLYKiJWQvaBBj7W4HjK4FRJiyRd6WbD2kkaA+wOzAOG13p+ljGZ9KSjpNVm\n/4jYC/gc2Qf2wEYHZFbh18B2EbE7sAK4tMHx9CmSBgM3AmekGkrN35llTCbPA/lOj9sCLzYollJI\nv0yIiJeAm8maEq0+KyUNB5A0AljV4Hj6tIh4Kd69NXUWsHcj4+lL0qjrNwK/j4jOPns1n59lTCbv\ndJSUNICso+RtDY6pz5I0MP1q6Ryh4Ajg0cZG1SeJ99aabwNOTK+77HhrXXrP8UxfeJ0m4XO0FlcB\nj0fEZbmyms/PUvYzSbcFXkaWLGdHxPT1rGJdSOOi3UxW7e0PXOfjWRtJfyDrnDsUWAmcD9wC/Bn4\nOPAscGxErG5UjH1JF8fzELL2/g5gOXBKZ5u/dU3SAWRjIj5C9hkP4EfAfOAGajg/S5lMzMxs4ypj\nM5eZmW1kTiZmZlY3JxMzM6ubk4mZmdXNycTMzOrmZGJmZnVzMrFSkNQh6Re56bMk/biXtt0iaVJv\nbGs9+/lyGgr8nqL3VbHfEyT9amPu08rHycTK4i1gkqQhjQ4kLz0SoadOBr4VEYcVFU833OHM6uJk\nYmWxDvgdcGbljMqahaTX09+DJbVKukXSk5KmSfqapAfTw8DG5jZzeBo1eYmkz6f1+0m6KC2/qHNE\n5bTd+yTdCjxeJZ7Jkh5O/6alsvOAA4HZkmZUWecHkuan/ZyfykZLWizp2lSjuUHSh9K8w9JDoh5K\no+humsr3lnR/2s68NEQOwEhJf0sPQ5qRe38tKc6HJJ1R4/+JNZH+jQ7ArJcEcDnwSLUv4yrLdtoV\nGA+sBp4GZkXEvumJc6fzbnIaHRF7S9oeuFfSdmRjFq1Oyw8A7pd0Z1p+D2CXiHg2v2NJWwPT0/zV\nwF2SjoqIn0o6lOxBRQsr1jkcGBcR+0gScFsaufk5YEfgpIiYJ2k28D1Jl5M9QOqQiHhK0jXAdyX9\nhuz5PsdGRFsac+1/aTe7kQ1HshZYKumXwHBgZETsmuL4yHqOqzUx10ysNNLQ2dcAtfyCXhARqyLi\nbeApoDMZPAKMyS13Q9rHk2m58WSDXh4vaSHwIDAEGJeWn1+ZSJK9gXsj4tWI6ACuAw7Kza/2CIUj\nyGpGbUAbWQLp3M+zETEvvb6WrHazI/B0RDyVyq9J+9gReDEi2tJ7eSMi2tMy96Tpt8hqU6PJkutY\nSZdJOhJ4vUpsZoBrJlY+l5F94bbkytbx3h9OA3Kv38q97shNd/Dez0e+NqM0LeD0iLgrH4Ckg4E1\nXcRXOXpwTwiYFhGzKvYzusqynXFV20d3+80fh3agf0SslrQb2SNyTwG+QnZdx+x9XDOxshBARLxG\nVovIf+ktB/YCkHQMsOkGbP9YZbYDxgJLgTlkzUr907bHSRq4nu08CBwkaYikTYDJQOt61pkDfLPz\n+oakbSQNS/NGSdo3vZ4M/ANYAoyW9IlU/o20jyXA1pI+lbYzOMVQlaShwCYRcTNwHlnTnFlVrplY\nWeRrDpcAp+bKZgG3puaoOXRda+jujqZnyYbl3pxsePO3JV1J1hTWlq5lrGI9z8qOiBWSzuXdBPLX\niLiju/1HxF2SxgP/ynbD68DXyWpPS8meftkCPAb8NiLeknQScGNKFguAKyJiraSvAjMlfRh4E/hM\nN8dhJNCS7kgLYEp3782am4egN+ujUjPXHRHxyUbHYuZmLrO+zb8G7QPBNRMzM6ubayZmZlY3JxMz\nM6ubk4mZmdXNycTMzOrmZGJmZnVzMjEzs7r9H+FdSHjwGHpJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd4a9ae5450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
